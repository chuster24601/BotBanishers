{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"L4RVotzHk1XO","executionInfo":{"status":"ok","timestamp":1681796895639,"user_tz":240,"elapsed":254,"user":{"displayName":"Ammar Safdari","userId":"18244085076020576291"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Xuh6tz96pe6j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681797132669,"user_tz":240,"elapsed":19812,"user":{"displayName":"Ammar Safdari","userId":"18244085076020576291"}},"outputId":"28224507-1e65-43a0-b394-30e7665f0f18"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","['GPT-wiki-intro.csv', 'Baseline.ipynb', 'Baseline_2', 'best_model.pkl', 'PyCaret.ipynb', 'Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv', 'human_reviews.csv', 'ai_reviews.csv', 'ai_reviews.gsheet', 'wiki_intros_human.csv', 'ai_wiki_intros_old.gsheet', 'ai_wiki_intros.csv', 'torch_embeddings_train.pt', 'torch_embeddings_test.pt', 'xgboost_model_embeddings.model', 'xgboost_model_extracted_features.model', 'extracted_features_test.csv', 'extracted_features_train.csv', 'glued_train.csv', 'glued_test.csv', 'xgboost_model_combined.model', 'y_train.csv', 'y_test.csv', 'Notebook.ipynb']\n","drive/My Drive/Classes Winter 2023/EECS 448 /Project 448/Environment\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","# TODO: change this to the path to your homework folder\n","#Sam: 'Class/Fourth Year classes/EECS 448/Project 448/Environment'\n","#Ammar: 'Classes Winter 2023/EECS 448 /Project 448/Environment'\n","#Cole: 'Project 448/Environment'\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'Classes Winter 2023/EECS 448 /Project 448/Environment'\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))\n","print(GOOGLE_DRIVE_PATH)\n","# Load the autoreload extension\n","%load_ext autoreload\n","%autoreload \n","import sys\n","sys.path.append(GOOGLE_DRIVE_PATH)\n","\n","# nb_path = '/content/notebooks'\n","# os.symlink('/content/gdrive/My Drive/Colab Notebooks', nb_path)\n","# sys.path.insert(0, nb_path)  # or append(nb_path)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QsrKM1AE9fj8"},"outputs":[],"source":["import xgboost\n","##do you want to save files this run??\n","save = True\n","\n","def load_xgb_model(filename):\n","  # Load the model from the file\n","  loaded_model = xgboost.XGBClassifier()\n","  loaded_model.load_model(GOOGLE_DRIVE_PATH +'/' + filename)\n","  return loaded_model"]},{"cell_type":"markdown","metadata":{"id":"dLy0xZ3RPc21"},"source":["Load/Examine Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M8abyQx0I7Rq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681267562660,"user_tz":240,"elapsed":23517,"user":{"displayName":"Sam You","userId":"01133282480618762281"}},"outputId":"81f83159-91cb-447f-f0b2-738c81fec31c"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-26-244f068cad02>:3: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n","\n","\n","  df = pd.read_csv(GOOGLE_DRIVE_PATH+ file_path, error_bad_lines = False, engine = \"python\")[:]\n"]}],"source":["#preprocess data\n","file_path = \"/GPT-wiki-intro.csv\"\n","df = pd.read_csv(GOOGLE_DRIVE_PATH+ file_path, error_bad_lines = False, engine = \"python\")[:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MTljwmExIpqV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681267562660,"user_tz":240,"elapsed":29,"user":{"displayName":"Sam You","userId":"01133282480618762281"}},"outputId":"798d309b-a828-444c-cc56-6787d65e9f32"},"outputs":[{"output_type":"stream","name":"stdout","text":["(150000, 12)\n"]}],"source":["#get subset for testing \n","print(df.shape)\n","dataset_size = 20000\n","generalized_set = df[149500:]\n","df = df[:dataset_size]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g_q9uhXZICRi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681267562660,"user_tz":240,"elapsed":25,"user":{"displayName":"Sam You","userId":"01133282480618762281"}},"outputId":"ddcbd11a-9ed2-43ef-a14b-bd12abfb2129"},"outputs":[{"output_type":"stream","name":"stdout","text":["(20000, 12)\n","Index(['id', 'url', 'title', 'wiki_intro', 'generated_intro', 'title_len',\n","       'wiki_intro_len', 'generated_intro_len', 'prompt', 'generated_text',\n","       'prompt_tokens', 'generated_text_tokens'],\n","      dtype='object')\n"]}],"source":["#Explore dataset\n","print(df.shape)\n","print(df.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vb99-SDI7mMK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681267562660,"user_tz":240,"elapsed":22,"user":{"displayName":"Sam You","userId":"01133282480618762281"}},"outputId":"26f7595f-e4df-4036-bab1-6c8f7967c846"},"outputs":[{"output_type":"stream","name":"stdout","text":["0      Sexhow railway station\n","1                    Etiäinen\n","2    Inverse function theorem\n","3           Stepping on Roses\n","4                 Rob Bradley\n","5                   Moluccans\n","6                   HarperOne\n","7     Full employment theorem\n","8           Pussy Fairy (OTW)\n","9                Qasr Ibrahim\n","Name: title, dtype: object\n","is a Japanese shōjo manga series written and illustrated by Rinko Ueda. The series began serialization in Margaret magazine in 2007 and completed its run in the March 19, 2012 issue of the same magazine. The individual chapters have been collected into eight tankōbon volumes by Shueisha as of March 2012; the first on April 25, 2008 and the most recent on October 25, 2011. The series has been licensed by Viz Media for an English-language North American release as part of their Shojo Beat imprint. Plot\n","During the year Meiji 25 (1892,) Sumi Kitamura is penniless and her brother Eisuke, a womanizer and gambler, constantly leaves them in debt while bringing even more orphaned children home to feed. When her adopted sister, Tomi, becomes ill, Sumi finds that no doctors will help her as they are poor and no one is willing to give her money for medicine to save Tomi. Then as Sumi is crying on the road a handsome man gives her a handkerchief and some money, telling her to stop crying as smiles beckon happiness into her life before disappearing. Later a debt collector turns up at Sumi's house demanding 2000 yen. Eisuke is nowhere to be found and it is revealed that he had been making advances on the debt collector's wife. The man says that he will take away all of Sumi's younger siblings and sell them into slavery. Desperate to save her siblings, Sumi goes to the red light district in an attempt to raise the money in one night. Just when she thinks there's no more hope, a man named Soichiro Ashida appears and says that he will buy her. Sumi goes with him only to find that he was paying her to marry him! They immediately go to the church and afterwards he says that he'll pay for anything she could possibly want, but she has to marry him and not fall for him and that he will never love her. Sumi agrees and they get married.\n","---\n","is a Japanese shōjo manga series written and illustrated by Maki Fujii. The series follows the life of Nanami Takahashi, a high school student who is struggling to find her place in the world.\n","\n","Nanami Takahashi has always been a bit of an outsider. She's not verypopular at school, and she doesn't have many friends. That's why she's excited when she gets a new couch to sit on at her grandparent's house. But when Nanami steps on one of the roses in her grandfather's garden, she accidentally destroys them. The Roses are special to him and Nanami feels really bad. She decides to try and make up for it by doing some chores for her grandparent, but things don't go as planned...\n"]}],"source":["print(df[\"title\"][:10])\n","print(df[\"wiki_intro\"][3])\n","print(\"---\")\n","print(df[\"generated_intro\"][3])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Lcj67ha71en","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681267562661,"user_tz":240,"elapsed":21,"user":{"displayName":"Sam You","userId":"01133282480618762281"}},"outputId":"2ef174b2-2b16-48a9-ed27-31bdc130634c"},"outputs":[{"output_type":"stream","name":"stdout","text":["<bound method NDFrame.head of              id                                                url  \\\n","0      63064638  https://en.wikipedia.org/wiki/Sexhow%20railway...   \n","1        279621        https://en.wikipedia.org/wiki/Eti%C3%A4inen   \n","2        287229  https://en.wikipedia.org/wiki/Inverse%20functi...   \n","3      26712375  https://en.wikipedia.org/wiki/Stepping%20on%20...   \n","4      38894426        https://en.wikipedia.org/wiki/Rob%20Bradley   \n","...         ...                                                ...   \n","19995  29636641  https://en.wikipedia.org/wiki/Swiss%20Criminal...   \n","19996   2733372       https://en.wikipedia.org/wiki/Turkish%20Left   \n","19997  50783123    https://en.wikipedia.org/wiki/Bernard%20Cousino   \n","19998  58020192  https://en.wikipedia.org/wiki/Guidoriccio%20da...   \n","19999   4627701       https://en.wikipedia.org/wiki/L%C3%BC%20Long   \n","\n","                          title  \\\n","0        Sexhow railway station   \n","1                      Etiäinen   \n","2      Inverse function theorem   \n","3             Stepping on Roses   \n","4                   Rob Bradley   \n","...                         ...   \n","19995       Swiss Criminal Code   \n","19996              Turkish Left   \n","19997           Bernard Cousino   \n","19998   Guidoriccio da Fogliano   \n","19999                   Lü Long   \n","\n","                                              wiki_intro  \\\n","0      Sexhow railway station was a railway station b...   \n","1      In Finnish folklore, all places and things, an...   \n","2      In mathematics, specifically differential calc...   \n","3      is a Japanese shōjo manga series written and i...   \n","4      Robert Milner \"Rob\" Bradley, Jr. (born August ...   \n","...                                                  ...   \n","19995  The Swiss Criminal Code (SR/RS 311, , , , ) is...   \n","19996  Turkish Left (in Turkish: Türk Solu) was a wee...   \n","19997  Bernard August Cousino (1 August 1902 – 29 Dec...   \n","19998  Guidoriccio da Fogliano (c. 1290 - 16 June 135...   \n","19999  Lü Long (; died 416), courtesy name Yongji (永基...   \n","\n","                                         generated_intro  title_len  \\\n","0      Sexhow railway station was a railway station l...          3   \n","1      In Finnish folklore, all places and things, an...          1   \n","2      In mathematics, specifically differential calc...          3   \n","3      is a Japanese shōjo manga series written and i...          3   \n","4      Robert Milner \"Rob\" Bradley, Jr. (born August ...          2   \n","...                                                  ...        ...   \n","19995  The Swiss Criminal Code (SR/RS 311, , also kno...          3   \n","19996  Turkish Left (in Turkish: Türk Solu) was an um...          2   \n","19997  Bernard August Cousino (1 August 1902 – 8 Sept...          2   \n","19998  Guidoriccio da Fogliano (c. 1290 - 16 October ...          3   \n","19999  Lü Long (; died 416), courtesy name Zhongyuan ...          2   \n","\n","       wiki_intro_len  generated_intro_len  \\\n","0                 174                   78   \n","1                 187                   80   \n","2                 170                   59   \n","3                 335                  121   \n","4                 170                  136   \n","...               ...                  ...   \n","19995             184                  154   \n","19996             152                  114   \n","19997             217                  152   \n","19998             214                  158   \n","19999             215                  210   \n","\n","                                                  prompt  \\\n","0      200 word wikipedia style introduction on 'Sexh...   \n","1      200 word wikipedia style introduction on 'Etiä...   \n","2      200 word wikipedia style introduction on 'Inve...   \n","3      200 word wikipedia style introduction on 'Step...   \n","4      200 word wikipedia style introduction on 'Rob ...   \n","...                                                  ...   \n","19995  200 word wikipedia style introduction on 'Swis...   \n","19996  200 word wikipedia style introduction on 'Turk...   \n","19997  200 word wikipedia style introduction on 'Bern...   \n","19998  200 word wikipedia style introduction on 'Guid...   \n","19999  200 word wikipedia style introduction on 'Lü L...   \n","\n","                                          generated_text  prompt_tokens  \\\n","0       located in the town of Sexhow, on the Cumbria...             25   \n","1       animate or inanimate, have a spirit or \"etiäi...             26   \n","2       function theorem states that for every real-v...             26   \n","3       and illustrated by Maki Fujii. The series fol...             26   \n","4       29, 1973) is an American former professional ...             28   \n","...                                                  ...            ...   \n","19995   also known as the Swiss Penal Code) is the cr...             28   \n","19996   an umbrella term for a number of left-wing po...             28   \n","19997   8 September 1978) was a Swiss-born Italian co...             26   \n","19998   October 1348) was an Italian painter, the son...             37   \n","19999   Zhongyuan (仲元), formally Duke Zhaozhou (昭周公),...             26   \n","\n","       generated_text_tokens  \n","0                         88  \n","1                        101  \n","2                         65  \n","3                        150  \n","4                        162  \n","...                      ...  \n","19995                    180  \n","19996                    141  \n","19997                    204  \n","19998                    213  \n","19999                    300  \n","\n","[20000 rows x 12 columns]>\n"]}],"source":["print(df.head)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KXwl2_NVvHZj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681267562661,"user_tz":240,"elapsed":16,"user":{"displayName":"Sam You","userId":"01133282480618762281"}},"outputId":"0116293d-76ae-4808-b31a-6ed7eedb61ff"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method NDFrame.head of              id                                                url  \\\n","0      63064638  https://en.wikipedia.org/wiki/Sexhow%20railway...   \n","1        279621        https://en.wikipedia.org/wiki/Eti%C3%A4inen   \n","2        287229  https://en.wikipedia.org/wiki/Inverse%20functi...   \n","3      26712375  https://en.wikipedia.org/wiki/Stepping%20on%20...   \n","4      38894426        https://en.wikipedia.org/wiki/Rob%20Bradley   \n","...         ...                                                ...   \n","19995  29636641  https://en.wikipedia.org/wiki/Swiss%20Criminal...   \n","19996   2733372       https://en.wikipedia.org/wiki/Turkish%20Left   \n","19997  50783123    https://en.wikipedia.org/wiki/Bernard%20Cousino   \n","19998  58020192  https://en.wikipedia.org/wiki/Guidoriccio%20da...   \n","19999   4627701       https://en.wikipedia.org/wiki/L%C3%BC%20Long   \n","\n","                          title  \\\n","0        Sexhow railway station   \n","1                      Etiäinen   \n","2      Inverse function theorem   \n","3             Stepping on Roses   \n","4                   Rob Bradley   \n","...                         ...   \n","19995       Swiss Criminal Code   \n","19996              Turkish Left   \n","19997           Bernard Cousino   \n","19998   Guidoriccio da Fogliano   \n","19999                   Lü Long   \n","\n","                                              wiki_intro  \\\n","0      Sexhow railway station was a railway station b...   \n","1      In Finnish folklore, all places and things, an...   \n","2      In mathematics, specifically differential calc...   \n","3      is a Japanese shōjo manga series written and i...   \n","4      Robert Milner \"Rob\" Bradley, Jr. (born August ...   \n","...                                                  ...   \n","19995  The Swiss Criminal Code (SR/RS 311, , , , ) is...   \n","19996  Turkish Left (in Turkish: Türk Solu) was a wee...   \n","19997  Bernard August Cousino (1 August 1902 – 29 Dec...   \n","19998  Guidoriccio da Fogliano (c. 1290 - 16 June 135...   \n","19999  Lü Long (; died 416), courtesy name Yongji (永基...   \n","\n","                                         generated_intro  title_len  \\\n","0      Sexhow railway station was a railway station l...          3   \n","1      In Finnish folklore, all places and things, an...          1   \n","2      In mathematics, specifically differential calc...          3   \n","3      is a Japanese shōjo manga series written and i...          3   \n","4      Robert Milner \"Rob\" Bradley, Jr. (born August ...          2   \n","...                                                  ...        ...   \n","19995  The Swiss Criminal Code (SR/RS 311, , also kno...          3   \n","19996  Turkish Left (in Turkish: Türk Solu) was an um...          2   \n","19997  Bernard August Cousino (1 August 1902 – 8 Sept...          2   \n","19998  Guidoriccio da Fogliano (c. 1290 - 16 October ...          3   \n","19999  Lü Long (; died 416), courtesy name Zhongyuan ...          2   \n","\n","       wiki_intro_len  generated_intro_len  \\\n","0                 174                   78   \n","1                 187                   80   \n","2                 170                   59   \n","3                 335                  121   \n","4                 170                  136   \n","...               ...                  ...   \n","19995             184                  154   \n","19996             152                  114   \n","19997             217                  152   \n","19998             214                  158   \n","19999             215                  210   \n","\n","                                                  prompt  \\\n","0      200 word wikipedia style introduction on 'Sexh...   \n","1      200 word wikipedia style introduction on 'Etiä...   \n","2      200 word wikipedia style introduction on 'Inve...   \n","3      200 word wikipedia style introduction on 'Step...   \n","4      200 word wikipedia style introduction on 'Rob ...   \n","...                                                  ...   \n","19995  200 word wikipedia style introduction on 'Swis...   \n","19996  200 word wikipedia style introduction on 'Turk...   \n","19997  200 word wikipedia style introduction on 'Bern...   \n","19998  200 word wikipedia style introduction on 'Guid...   \n","19999  200 word wikipedia style introduction on 'Lü L...   \n","\n","                                          generated_text  prompt_tokens  \\\n","0       located in the town of Sexhow, on the Cumbria...             25   \n","1       animate or inanimate, have a spirit or \"etiäi...             26   \n","2       function theorem states that for every real-v...             26   \n","3       and illustrated by Maki Fujii. The series fol...             26   \n","4       29, 1973) is an American former professional ...             28   \n","...                                                  ...            ...   \n","19995   also known as the Swiss Penal Code) is the cr...             28   \n","19996   an umbrella term for a number of left-wing po...             28   \n","19997   8 September 1978) was a Swiss-born Italian co...             26   \n","19998   October 1348) was an Italian painter, the son...             37   \n","19999   Zhongyuan (仲元), formally Duke Zhaozhou (昭周公),...             26   \n","\n","       generated_text_tokens  \n","0                         88  \n","1                        101  \n","2                         65  \n","3                        150  \n","4                        162  \n","...                      ...  \n","19995                    180  \n","19996                    141  \n","19997                    204  \n","19998                    213  \n","19999                    300  \n","\n","[20000 rows x 12 columns]>"]},"metadata":{},"execution_count":31}],"source":["df.head"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HYD4P8iQORes","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681267562661,"user_tz":240,"elapsed":11,"user":{"displayName":"Sam You","userId":"01133282480618762281"}},"outputId":"f4fa34ce-9ffe-4d2e-9f9c-c0207e86b8ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["count    20000.000000\n","mean       195.679850\n","std         41.199521\n","min        150.000000\n","25%        164.000000\n","50%        184.000000\n","75%        216.000000\n","max        350.000000\n","Name: wiki_intro_len, dtype: float64\n","count    20000.000000\n","mean       129.318000\n","std         56.793549\n","min          7.000000\n","25%         86.000000\n","50%        122.000000\n","75%        169.000000\n","max        275.000000\n","Name: generated_intro_len, dtype: float64\n"]}],"source":["df.columns\n","print(df[\"wiki_intro_len\"].describe())\n","print(df[\"generated_intro_len\"].describe())"]},{"cell_type":"markdown","metadata":{"id":"4xQwievpPmwN"},"source":["Create Train/Test Split (pyCaret Does Validation)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hSSXlFRe-uOP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681267562661,"user_tz":240,"elapsed":7,"user":{"displayName":"Sam You","userId":"01133282480618762281"}},"outputId":"43ade8f9-a599-423d-823f-233bf4073768"},"outputs":[{"output_type":"stream","name":"stdout","text":["<bound method NDFrame.head of              id                                                url  \\\n","0      63064638  https://en.wikipedia.org/wiki/Sexhow%20railway...   \n","1        279621        https://en.wikipedia.org/wiki/Eti%C3%A4inen   \n","2        287229  https://en.wikipedia.org/wiki/Inverse%20functi...   \n","3      26712375  https://en.wikipedia.org/wiki/Stepping%20on%20...   \n","4      38894426        https://en.wikipedia.org/wiki/Rob%20Bradley   \n","...         ...                                                ...   \n","19995  29636641  https://en.wikipedia.org/wiki/Swiss%20Criminal...   \n","19996   2733372       https://en.wikipedia.org/wiki/Turkish%20Left   \n","19997  50783123    https://en.wikipedia.org/wiki/Bernard%20Cousino   \n","19998  58020192  https://en.wikipedia.org/wiki/Guidoriccio%20da...   \n","19999   4627701       https://en.wikipedia.org/wiki/L%C3%BC%20Long   \n","\n","                          title  \\\n","0        Sexhow railway station   \n","1                      Etiäinen   \n","2      Inverse function theorem   \n","3             Stepping on Roses   \n","4                   Rob Bradley   \n","...                         ...   \n","19995       Swiss Criminal Code   \n","19996              Turkish Left   \n","19997           Bernard Cousino   \n","19998   Guidoriccio da Fogliano   \n","19999                   Lü Long   \n","\n","                                              wiki_intro  \\\n","0      Sexhow railway station was a railway station b...   \n","1      In Finnish folklore, all places and things, an...   \n","2      In mathematics, specifically differential calc...   \n","3      is a Japanese shōjo manga series written and i...   \n","4      Robert Milner \"Rob\" Bradley, Jr. (born August ...   \n","...                                                  ...   \n","19995  The Swiss Criminal Code (SR/RS 311, , , , ) is...   \n","19996  Turkish Left (in Turkish: Türk Solu) was a wee...   \n","19997  Bernard August Cousino (1 August 1902 – 29 Dec...   \n","19998  Guidoriccio da Fogliano (c. 1290 - 16 June 135...   \n","19999  Lü Long (; died 416), courtesy name Yongji (永基...   \n","\n","                                         generated_intro  title_len  \\\n","0      Sexhow railway station was a railway station l...          3   \n","1      In Finnish folklore, all places and things, an...          1   \n","2      In mathematics, specifically differential calc...          3   \n","3      is a Japanese shōjo manga series written and i...          3   \n","4      Robert Milner \"Rob\" Bradley, Jr. (born August ...          2   \n","...                                                  ...        ...   \n","19995  The Swiss Criminal Code (SR/RS 311, , also kno...          3   \n","19996  Turkish Left (in Turkish: Türk Solu) was an um...          2   \n","19997  Bernard August Cousino (1 August 1902 – 8 Sept...          2   \n","19998  Guidoriccio da Fogliano (c. 1290 - 16 October ...          3   \n","19999  Lü Long (; died 416), courtesy name Zhongyuan ...          2   \n","\n","       wiki_intro_len  generated_intro_len  \\\n","0                 174                   78   \n","1                 187                   80   \n","2                 170                   59   \n","3                 335                  121   \n","4                 170                  136   \n","...               ...                  ...   \n","19995             184                  154   \n","19996             152                  114   \n","19997             217                  152   \n","19998             214                  158   \n","19999             215                  210   \n","\n","                                                  prompt  \\\n","0      200 word wikipedia style introduction on 'Sexh...   \n","1      200 word wikipedia style introduction on 'Etiä...   \n","2      200 word wikipedia style introduction on 'Inve...   \n","3      200 word wikipedia style introduction on 'Step...   \n","4      200 word wikipedia style introduction on 'Rob ...   \n","...                                                  ...   \n","19995  200 word wikipedia style introduction on 'Swis...   \n","19996  200 word wikipedia style introduction on 'Turk...   \n","19997  200 word wikipedia style introduction on 'Bern...   \n","19998  200 word wikipedia style introduction on 'Guid...   \n","19999  200 word wikipedia style introduction on 'Lü L...   \n","\n","                                          generated_text  prompt_tokens  \\\n","0       located in the town of Sexhow, on the Cumbria...             25   \n","1       animate or inanimate, have a spirit or \"etiäi...             26   \n","2       function theorem states that for every real-v...             26   \n","3       and illustrated by Maki Fujii. The series fol...             26   \n","4       29, 1973) is an American former professional ...             28   \n","...                                                  ...            ...   \n","19995   also known as the Swiss Penal Code) is the cr...             28   \n","19996   an umbrella term for a number of left-wing po...             28   \n","19997   8 September 1978) was a Swiss-born Italian co...             26   \n","19998   October 1348) was an Italian painter, the son...             37   \n","19999   Zhongyuan (仲元), formally Duke Zhaozhou (昭周公),...             26   \n","\n","       generated_text_tokens  \n","0                         88  \n","1                        101  \n","2                         65  \n","3                        150  \n","4                        162  \n","...                      ...  \n","19995                    180  \n","19996                    141  \n","19997                    204  \n","19998                    213  \n","19999                    300  \n","\n","[20000 rows x 12 columns]>\n","----\n","<bound method NDFrame.head of                                                     text\n","0      Sexhow railway stationSexhow railway station w...\n","1      EtiäinenIn Finnish folklore, all places and th...\n","2      Inverse function theoremIn mathematics, specif...\n","3      Stepping on Rosesis a Japanese shōjo manga ser...\n","4      Rob BradleyRobert Milner \"Rob\" Bradley, Jr. (b...\n","...                                                  ...\n","19994  David Stewart DawsonDavid Stewart Dawson (1849...\n","19995  Swiss Criminal CodeThe Swiss Criminal Code (SR...\n","19996  Turkish LeftTurkish Left (in Turkish: Türk Sol...\n","19997  Bernard CousinoBernard August Cousino (1 Augus...\n","19998  Guidoriccio da FoglianoGuidoriccio da Fogliano...\n","\n","[14317 rows x 1 columns]>\n","<bound method NDFrame.head of                                                     text\n","5      MoluccansMoluccans are the Austronesian-speaki...\n","12     FORGE ProgramFORGE is a United States-based no...\n","15     Borderland (book series)The Borderland series ...\n","18     History of MadagascarThe history of Madagascar...\n","22     Mel Roberts (baseball)Melvin Henry Roberts (Ja...\n","...                                                  ...\n","19984  1896–1897 Macedonian rebellionThe 1896–1897 Ma...\n","19988  Feminist AssociationThe Hungarian Feminist Ass...\n","19989  Craig RaineCraig Anthony Raine, FRSL (born 3 D...\n","19990  NERACNerac, Inc. is a research and advisory co...\n","19999  Lü LongLü Long (; died 416), courtesy name Zho...\n","\n","[5683 rows x 1 columns]>\n"]}],"source":["#Explore dataset\n","train_test_split = 0.75\n","\n","\n","human = df.copy()\n","gpt = df.copy()\n","human = human.loc[human['generated_intro_len'] <= 160]\n","gpt = gpt.loc[gpt['generated_intro_len'] > 160]\n","\n","human['text'] = human['title'] + human['wiki_intro']\n","gpt['text'] = gpt['title'] + gpt['generated_intro']\n","human = human[['text']]\n","gpt = gpt[['text']]\n","\n","#human_test = human_test.iloc[gpt_test.index]\n","\n","# human = human.iloc[::2, :]\n","# gpt = gpt.iloc[1::2, :]\n","\n","human = human.iloc[::1, :]\n","gpt = gpt.iloc[::1, :]\n","\n","print(df.head)\n","print(\"----\")\n","print(human.head)\n","print(gpt.head)\n","\n","#add label for train\n","human['label'] = 1.0\n","gpt['label'] = 0.0\n","\n","#stack dataframes and shuffle to create train set\n","from sklearn.utils import shuffle\n","\n","dataset = pd.concat([human, gpt], ignore_index=True)\n","#shuffle dataset for later batch processing\n","dataset = shuffle(dataset)\n","\n","train = dataset.iloc[:int(np.floor(df.shape[0] * train_test_split))]\n","\n","#subtract 2 to prevent train/test independence violation\n","test = dataset.tail(int(np.floor(df.shape[0] * (1 - train_test_split) - 2)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RWGBuUgBJPor","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681267562661,"user_tz":240,"elapsed":6,"user":{"displayName":"Sam You","userId":"01133282480618762281"}},"outputId":"4d8d60d7-fbd9-4585-eb11-c5c6bc8ed020"},"outputs":[{"output_type":"stream","name":"stdout","text":["(15000, 2)\n","                                                    text  label\n","10512  Elizabeth VandiverElizabeth Vandiver (born 195...    1.0\n","10819  Nathaniel Drake HouseThe Nathaniel Drake House...    1.0\n","7445   Dennis HeeneyDennis Heeney was a Manitoba poli...    1.0\n","11283  Tsumugi (cloth)is a traditional slub silk clot...    1.0\n","19551  Jeffrey G. WilliamsonJeffrey Gale Williamson (...    0.0\n","...                                                  ...    ...\n","1018   History of PlymouthThe History of Plymouth in ...    1.0\n","17392  KidsongsKidsongs is an American children's med...    0.0\n","8021   ManchaliManchali is a 1973 Hindi romantic dram...    1.0\n","18578  Todd RasmussenTodd E. Rasmussen, MD, FACS is a...    0.0\n","8704   GerlachGerlach is a male forename of Germanic ...    1.0\n","\n","[15000 rows x 2 columns]\n"]}],"source":["print(train.shape)\n","train.head\n","train.columns\n","print(train)"]},{"cell_type":"markdown","metadata":{"id":"vf35B9DuPuQu"},"source":["Preprocess Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1LFZRmRtH0kQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681267563244,"user_tz":240,"elapsed":463,"user":{"displayName":"Sam You","userId":"01133282480618762281"}},"outputId":"dda9a05b-b0a2-4a46-adb0-3a5be1621ee5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement re (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for re\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install re\n","import re #I'm pretty sure we don't need this\n","def removeHTML(x):\n","    html=re.compile(r'<.*?>')\n","    return html.sub(r'',x)\n","\n","def dataPreprocessing(x):    \n","    x = x.lower()\n","    x = removeHTML(x)\n","    x = re.sub(\"@\\w+\", '',x) # removing mentions (@)\n","    x = re.sub(\"'\\d+\", '',x)\n","    x = re.sub(\"\\d+\", '',x)\n","    re.sub(r'http\\S+', '', x) # remove links\n","    x = re.sub(r\"[^\\w\\s]\", '',x) # to remove symbols\n","    x = re.sub(\"\\s[a-z]\\s\", ' ',x) #single charcaters\n","    x = re.sub(r'\\n', ' ', x) #newlines\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ileOW9Ey_jN1"},"outputs":[],"source":["train_no_delim = train[\"text\"].apply(lambda x: dataPreprocessing(x))\n","test_no_delim = test[\"text\"].apply(lambda x: dataPreprocessing(x))\n","\n","train_no_delim = train_no_delim.to_frame()\n","test_no_delim = test_no_delim.to_frame()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-tAVHT4N_vfW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681267564907,"user_tz":240,"elapsed":8,"user":{"displayName":"Sam You","userId":"01133282480618762281"}},"outputId":"0e395372-8f7f-433c-a124-b227734b28f6"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import nltk\n","from nltk import word_tokenize\n","from nltk.lm.preprocessing import padded_everygram_pipeline\n","from collections import Counter\n","\n","nltk.download('punkt')\n","\n","from nltk.lm import MLE\n","from nltk.lm.preprocessing import padded_everygram_pipeline\n","\n","#maybe use spacy library \n","\n","# this was part of an attempt to extract perplexity from our data\n","# n = 4\n","# train_data = train_no_delim[train['label'] == 1]\n","# print(train_data.head)\n","# tokens = nltk.word_tokenize(' '.join( train_data ))\n","# train_data, padded_vocab = padded_everygram_pipeline(n, tokens)\n","# model = MLE(n)\n","# model.fit(train_data, padded_vocab)\n"]},{"cell_type":"markdown","metadata":{"id":"XkckQgVIQHYX"},"source":["Get BERT Encodings"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"mnUAMkyqKViw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681797178609,"user_tz":240,"elapsed":131,"user":{"displayName":"Ammar Safdari","userId":"18244085076020576291"}},"outputId":"f3b4e4e3-7241-4c1b-a32a-b0e9bccebafb"},"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","cuda:0\n"]}],"source":["# Load torch\n","import torch\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(torch.cuda.is_available())\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mYmFcidSKcmy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681267565081,"user_tz":240,"elapsed":4,"user":{"displayName":"Sam You","userId":"01133282480618762281"}},"outputId":"e6c30bab-565f-4b33-a2b1-62b2d8c927b5"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["<bound method NDFrame.head of 0        elizabeth vandiverelizabeth vandiver born  is ...\n","1        nathaniel drake housethe nathaniel drake house...\n","2        dennis heeneydennis heeney was manitoba politi...\n","3        tsumugi clothis traditional slub silk cloth fr...\n","4        jeffrey williamsonjeffrey gale williamson born...\n","                               ...                        \n","19993    sannō temple ruinsis an archaeological site wi...\n","19994    laurel canyon boulevardlaurel canyon boulevard...\n","19995    maitama suleyusuf maitama sule   october    ma...\n","19996    augustus buchelaugustus carl buchel october   ...\n","19997    observational learningobservational learning i...\n","Name: text, Length: 19998, dtype: object>"]},"metadata":{},"execution_count":39}],"source":["# tokenize words\n","import nltk\n","nltk.download('stopwords')\n","\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.stem import PorterStemmer\n","from nltk.corpus import stopwords\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import roc_auc_score, f1_score\n","from scipy.sparse import hstack\n","stopwords = stopwords.words('english')\n","stopwords = stopwords[:116]\n","stopwords = stopwords.extend(['d', 'll', 're', 's', 've'])\n","data = pd.concat([train_no_delim, test_no_delim], axis=0).reset_index(drop = True)[\"text\"]\n","data.head"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h-zjrhxo0ASC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681267565082,"user_tz":240,"elapsed":3,"user":{"displayName":"Sam You","userId":"01133282480618762281"}},"outputId":"ee15fa13-e5e5-4937-b5b8-c910399bb8ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["0        elizabeth vandiverelizabeth vandiver born  is ...\n","1        nathaniel drake housethe nathaniel drake house...\n","2        dennis heeneydennis heeney was manitoba politi...\n","3        tsumugi clothis traditional slub silk cloth fr...\n","4        jeffrey williamsonjeffrey gale williamson born...\n","                               ...                        \n","19993    sannō temple ruinsis an archaeological site wi...\n","19994    laurel canyon boulevardlaurel canyon boulevard...\n","19995    maitama suleyusuf maitama sule   october    ma...\n","19996    augustus buchelaugustus carl buchel october   ...\n","19997    observational learningobservational learning i...\n","Name: text, Length: 19998, dtype: object\n"]}],"source":["print(data)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"48k5vp7ELaCn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681797214851,"user_tz":240,"elapsed":33144,"user":{"displayName":"Ammar Safdari","userId":"18244085076020576291"}},"outputId":"81049900-6062-4319-e06f-b1ef1b0c9b45"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["!pip install transformers\n","from torch import nn\n","\n","from transformers import RobertaTokenizer, RobertaModel\n","from transformers import AdamW\n","from tqdm import tqdm\n","class BertClassificationModel(nn.Module):\n","    def __init__(self,hidden_size=768,num_class=2): \n","        super(BertClassificationModel, self).__init__()\n","        model_name = \"roberta-base\"\n","        self.tokenizer = RobertaTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)\n","        self.bert = RobertaModel.from_pretrained(pretrained_model_name_or_path=model_name)\n","\n","        for p in self.bert.parameters(): \n","                p.requires_grad = False\n","        self.fc = nn.Linear(hidden_size, num_class)\n","\n","    def forward(self, batch_sentences): \n","        sentences_tokenizer = self.tokenizer(batch_sentences,\n","                                             truncation=True,\n","                                             padding=True,\n","                                             max_length=512,\n","                                             add_special_tokens=True)\n","        input_ids=torch.tensor(sentences_tokenizer['input_ids']).to(device) \n","        attention_mask=torch.tensor(sentences_tokenizer['attention_mask']).to(device) \n","        bert_out=self.bert(input_ids=input_ids,attention_mask=attention_mask) \n","\n","        last_hidden_state =bert_out[0].to(device) \n","        bert_cls_hidden_state=last_hidden_state[:,0,:].to(device) \n","        return bert_cls_hidden_state\n","model=BertClassificationModel()\n","model=model.to(device)"]},{"cell_type":"code","source":["#try perplexity \n","# from transformers import RobertaForMaskedLM, RobertaTokenizer\n","\n","# # Load pre-trained RoBERTa model and tokenizer\n","# model = RobertaForMaskedLM.from_pretrained('roberta-base')\n","# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","\n","# # New text to calculate perplexity for\n","# new_text = \"Sexhow railway station was a railway station built to serve the hamlet of Sexhow in North Yorkshire, England.\"\n","\n","# # Tokenize the new text\n","# input_ids = tokenizer.encode(new_text, add_special_tokens=True, return_tensors='pt')\n","\n","# # Calculate the log probabilities of the sequence\n","# with torch.no_grad():\n","#     outputs = model(input_ids)\n","#     logits = outputs.logits\n","#     log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n","\n","# # Calculate the perplexity\n","# log_likelihood = torch.sum(log_probs, dim=-1)\n","# perplexity = torch.exp(-log_likelihood.mean())\n","# print(f\"Perplexity: {perplexity.item():.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iSTN81P-6hvd","executionInfo":{"status":"ok","timestamp":1681797437941,"user_tz":240,"elapsed":3009,"user":{"displayName":"Ammar Safdari","userId":"18244085076020576291"}},"outputId":"d7998fad-c7b0-4ca0-cfdf-f0c07c98d623"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Perplexity: inf\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"01RCDnRQSHNB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681267577292,"user_tz":240,"elapsed":23,"user":{"displayName":"Sam You","userId":"01133282480618762281"}},"outputId":"30af252f-b3b7-4c3b-bb22-87a142c7d7f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['text'], dtype='object')\n"]}],"source":["print(train_no_delim.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9MggXjtLLy-W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681267899598,"user_tz":240,"elapsed":322326,"user":{"displayName":"Sam You","userId":"01133282480618762281"}},"outputId":"ab6a2df6-41c1-4c59-9676-153a3fef1b72"},"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['text'], dtype='object')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 15000/15000 [05:20<00:00, 46.79it/s]\n"]}],"source":["# transform text to BERT\n","torch_train = []\n","print(train_no_delim.columns)\n","for row in tqdm(train_no_delim['text']):\n","    input = row\n","\n","    torch_train.append(model([input]).cpu().detach().numpy())\n","torch_train = np.array(torch_train).reshape(-1,768)  \n","\n","if(save):\n","  # Save the tensor dataset to a file\n","  torch.save(torch_train, GOOGLE_DRIVE_PATH +  '/torch_embeddings_train.pt')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XxK-LL0iMNL4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681268020659,"user_tz":240,"elapsed":121066,"user":{"displayName":"Sam You","userId":"01133282480618762281"}},"outputId":"2a682d3c-6a50-4f4f-c903-839a9a77df7c"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 4998/4998 [02:00<00:00, 41.57it/s]\n"]}],"source":["# transform text to BERT\n","torch_test = []\n","for row in tqdm(test_no_delim['text']):\n","    input = row\n","\n","    torch_test.append(model([input]).cpu().detach().numpy())\n","torch_test = np.array(torch_test).reshape(-1,768) \n","if(save):\n","  # Save the tensor dataset to a file\n","  torch.save(torch_test, GOOGLE_DRIVE_PATH +  '/torch_embeddings_test.pt')\n"]},{"cell_type":"markdown","metadata":{"id":"tikZTC2P40cw"},"source":["### Fit an XGB boost model on BERT encodings only"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pNSn3dIxzu1K"},"outputs":[],"source":["ytrain = train[\"label\"].values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7R5G6wVnbrX_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681268026662,"user_tz":240,"elapsed":6011,"user":{"displayName":"Sam You","userId":"01133282480618762281"}},"outputId":"cef1dfcd-49db-449a-bf3b-2b4bbc0bb3b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting bayesian-optimization\n","  Downloading bayesian_optimization-1.4.2-py3-none-any.whl (17 kB)\n","Collecting colorama>=0.4.6\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.9/dist-packages (from bayesian-optimization) (1.2.2)\n","Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from bayesian-optimization) (1.22.4)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from bayesian-optimization) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.1.0)\n","Installing collected packages: colorama, bayesian-optimization\n","Successfully installed bayesian-optimization-1.4.2 colorama-0.4.6\n"]}],"source":["!pip install bayesian-optimization"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cf2XL-RSzHBS","outputId":"a216767a-8642-4cb5-b3b7-b24af05734c1","executionInfo":{"status":"ok","timestamp":1681268149305,"user_tz":240,"elapsed":122648,"user":{"displayName":"Sam You","userId":"01133282480618762281"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["|   iter    |  target   | colsam... | learni... | max_depth | n_esti... | subsample |\n","-------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["3it [00:17,  5.74s/it]\n"]},{"output_type":"stream","name":"stdout","text":["| \u001b[0m1        \u001b[0m | \u001b[0m0.9399   \u001b[0m | \u001b[0m0.4176   \u001b[0m | \u001b[0m0.2661   \u001b[0m | \u001b[0m5.003    \u001b[0m | \u001b[0m311.6    \u001b[0m | \u001b[0m0.1476   \u001b[0m |\n"]},{"output_type":"stream","name":"stderr","text":["3it [00:39, 13.05s/it]\n"]},{"output_type":"stream","name":"stdout","text":["| \u001b[95m2        \u001b[0m | \u001b[95m0.9523   \u001b[0m | \u001b[95m0.09325  \u001b[0m | \u001b[95m0.1059   \u001b[0m | \u001b[95m13.64    \u001b[0m | \u001b[95m377.7    \u001b[0m | \u001b[95m0.5393   \u001b[0m |\n"]},{"output_type":"stream","name":"stderr","text":["3it [00:12,  4.21s/it]\n"]},{"output_type":"stream","name":"stdout","text":["| \u001b[0m3        \u001b[0m | \u001b[0m0.9384   \u001b[0m | \u001b[0m0.1169   \u001b[0m | \u001b[0m0.1586   \u001b[0m | \u001b[0m13.01    \u001b[0m | \u001b[0m376.5    \u001b[0m | \u001b[0m0.07359  \u001b[0m |\n"]},{"output_type":"stream","name":"stderr","text":["3it [00:29,  9.75s/it]\n"]},{"output_type":"stream","name":"stdout","text":["| \u001b[95m4        \u001b[0m | \u001b[95m0.9553   \u001b[0m | \u001b[95m0.3006   \u001b[0m | \u001b[95m0.1875   \u001b[0m | \u001b[95m19.65    \u001b[0m | \u001b[95m620.2    \u001b[0m | \u001b[95m0.4747   \u001b[0m |\n"]},{"output_type":"stream","name":"stderr","text":["3it [00:23,  7.91s/it]"]},{"output_type":"stream","name":"stdout","text":["| \u001b[95m5        \u001b[0m | \u001b[95m0.956    \u001b[0m | \u001b[95m0.7364   \u001b[0m | \u001b[95m0.2571   \u001b[0m | \u001b[95m7.397    \u001b[0m | \u001b[95m572.2    \u001b[0m | \u001b[95m0.6522   \u001b[0m |\n","=====================================================================================\n","{'target': 0.956, 'params': {'colsample_bytree': 0.7364426244740934, 'learning_rate': 0.2571381009492539, 'max_depth': 7.396611274638937, 'n_estimators': 572.2372832019864, 'subsample': 0.652224688908482}}\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","from sklearn.utils import class_weight\n","from xgboost import XGBClassifier\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import accuracy_score \n","from bayes_opt import BayesianOptimization\n","from sklearn.model_selection import KFold\n","# gamma,min_child_weight\n","def xgb_evaluate1(n_estimators,max_depth,subsample\n","                ,colsample_bytree,learning_rate):\n","    model=XGBClassifier(n_estimators=int(n_estimators),\n","                          max_depth=int(max_depth),\n","                          subsample=subsample,\n","                          colsample_bytree=colsample_bytree,\n","                          learning_rate=learning_rate,n_jobs=-1,\n","                          tree_method='gpu_hist',\n","                          predictor='gpu_predictor')\n","    rmse_scores=[]\n","    kf = KFold(n_splits = 3)\n","    for train_ix, test_ix in tqdm(kf.split(torch_train)):\n","        X_train, X_test = torch_train[train_ix], torch_train[test_ix]\n","        Y_train, Y_test = ytrain[train_ix], ytrain[test_ix]\n","        model.fit(X_train,Y_train,sample_weight=class_weight.compute_sample_weight(class_weight='balanced', y=Y_train))\n","        pred = model.predict(X_test)\n","        rmse_scores.append(accuracy_score(Y_test,pred))\n","    val=np.mean(rmse_scores)\n","    return val\n","pbounds = {'max_depth': (5, 30),\n","           'n_estimators': (100, 800),\n","           \"subsample\":(0.001, 1),\n","           \"colsample_bytree\":(0.001,1),\n","           \"learning_rate\":(0.05,0.35)}\n","xgb_bo = BayesianOptimization(\n","        f=xgb_evaluate1,   # Objective function\n","        pbounds=pbounds,  # Value space\n","        verbose=2,  # \n","        random_state=1,\n",")\n","xgb_bo.maximize(init_points=2,   # Steps of random search\n","                   n_iter=3,    # Number of iterations to perform Bayesian optimization\n","                   acq='ei',\n","                torch_train = torch_train)\n","print(xgb_bo.max)\n","res_xgb = xgb_bo.max\n","params_xgb1 = res_xgb['params']\n","for key in params_xgb1:\n","    if key in [\"max_depth\",\"scale_pos_weight\",\"n_estimators\"]:\n","        params_xgb1[key]=int(params_xgb1[key])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":284},"id":"3qmXOcpjzH9L","outputId":"2ae66431-7ddc-40e2-9853-d4eeaeb4de1b","executionInfo":{"status":"ok","timestamp":1681268190027,"user_tz":240,"elapsed":40743,"user":{"displayName":"Sam You","userId":"01133282480618762281"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["3it [00:27,  9.30s/it]\n"]},{"output_type":"stream","name":"stdout","text":["0.956\n"]},{"output_type":"execute_result","data":{"text/plain":["XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=0.7364426244740934, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.2571381009492539,\n","              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=7, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=572, n_jobs=-1, num_parallel_tree=None,\n","              predictor='gpu_predictor', random_state=None, ...)"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=0.7364426244740934, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.2571381009492539,\n","              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=7, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=572, n_jobs=-1, num_parallel_tree=None,\n","              predictor=&#x27;gpu_predictor&#x27;, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=0.7364426244740934, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.2571381009492539,\n","              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=7, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=572, n_jobs=-1, num_parallel_tree=None,\n","              predictor=&#x27;gpu_predictor&#x27;, random_state=None, ...)</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":48}],"source":["import xgboost\n","xgb_1= xgboost.XGBClassifier(**params_xgb1,tree_method='gpu_hist',\n","                    predictor='gpu_predictor',n_jobs=-1)\n","rmse_scores=[]\n","kf = KFold(n_splits = 3)\n","for train_ix, test_ix in tqdm(kf.split(torch_train)):\n","    X_train, X_test = torch_train[train_ix], torch_train[test_ix]\n","    Y_train, Y_test = ytrain[train_ix], ytrain[test_ix]\n","    xgb_1.fit(X_train,Y_train,sample_weight=class_weight.compute_sample_weight(class_weight='balanced', y=Y_train))\n","    pred = xgb_1.predict(X_test)\n","    rmse_scores.append(accuracy_score(Y_test,pred))\n","a=np.mean(rmse_scores)\n","print(a)\n","xgb_1.fit(torch_train,ytrain,sample_weight=class_weight.compute_sample_weight(class_weight='balanced', y=ytrain))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WDaLQlBF0Nm4"},"outputs":[],"source":["filename = \"xgboost_model_embeddings.model\"\n","if(save):\n","  xgb_1.save_model(GOOGLE_DRIVE_PATH + '/' + filename)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QDhgYOMoAi5x","outputId":"a3b9353b-f409-4446-e626-fe68c04bc164","executionInfo":{"status":"ok","timestamp":1681268190490,"user_tz":240,"elapsed":5,"user":{"displayName":"Sam You","userId":"01133282480618762281"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[155, 656, 749, 338, 698, 247, 672, 143, 94, 284]\n"]}],"source":["#see which are the msot important encoding features to the model\n","xgb_1 = load_xgb_model(\"xgboost_model_embeddings.model\")\n","\n","top_10_indices = np.flip(np.argsort(xgb_1.feature_importances_))[:10].tolist()\n","print(top_10_indices)\n"]},{"cell_type":"markdown","source":["Define Functions to Extract Additional Features from Text to Add to Data"],"metadata":{"id":"GcphGQbhBGGi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dYY1BjVm_U5M"},"outputs":[],"source":["import math\n","#perplexity not working!!\n","\n","def extract_perplexity(dataset, model, n):\n","    \"\"\"\n","    Extract the perplexity of each text sample in the given dataset.\n","    Takes a pandas DataFrame and returns a new DataFrame with a perplexity column.\n","    \"\"\"\n","    # Calculate the perplexity of each text sample using the model\n","    perplexities = []\n","  \n","    for i in range(dataset.shape[0]):\n","        text = dataset['text'][i]\n","        tokens = nltk.word_tokenize(text)\n","        test_data, _ = padded_everygram_pipeline(n, tokens[:-1])\n","        test_text = tokens[-1]\n","        log_prob = model.score(test_data, test_text)\n","        perplexity = math.exp(-log_prob)\n","        perplexities.append(perplexity)\n","    \n","    # Add the perplexity column to the dataset\n","    dataset['perplexity'] = perplexities\n","    \n","    return dataset\n","\n","\n","def avg_burstiness(text):\n","    \"\"\"\n","    Computes the avg burstiness of given text\n","    GPT-0 inspired\n","    \"\"\"\n","    # Split the text into words\n","    words = text.split()\n","    word_counts = Counter(words)\n","    average_burstiness = 0\n","    try:\n","      mean_frequency = sum(word_counts.values()) / len(word_counts)\n","      if len(word_counts) == 1:\n","          return 0 \n","      variance = sum((count - mean_frequency) ** 2 for count in word_counts.values()) / (len(word_counts) - 1)\n","      burstiness_scores = [(count - mean_frequency) / variance for count in word_counts.values()]\n","      average_burstiness = sum(burstiness_scores) / len(burstiness_scores)\n","    except:\n","      print(text)\n","    return average_burstiness\n","\n","def avg_sentence_length(text):\n","    \"\"\"\n","    Calculates the average length of sentences in the given text\n","    AI may have more standard sentence length with less variation\n","    \"\"\"\n","    sentences = re.split(r'[.?!]', text)\n","    lengths = [len(word_tokenize(sentence)) for sentence in sentences if len(sentence) > 0]\n","    return sum(lengths) / len(lengths)\n","\n","def vocabulary_richness(text):\n","    \"\"\"\n","    Calculates the ratio of unique words to total words in the given text.\n","    AI may have less rich vocabulary in its text\n","    \"\"\"\n","    tokens = word_tokenize(text.lower())\n","    unique_words = set(tokens)\n","    return len(unique_words) / len(tokens)\n","\n","extract_feature_functions = [ avg_burstiness, avg_sentence_length, vocabulary_richness]\n","\n","#we can keep trying to extract features that might be useful from the text \n","# def count_contractions(text):\n","#     \"\"\"\n","#     Counts the number of contractions in the given text.\n","#     \"\"\"\n","#     contractions = [\"'s\", \"'m\", \"'ve\", \"'re\", \"'d\", \"n't\", \"'ll\"]\n","#     tokens = word_tokenize(text.lower())\n","#     count = sum([1 for token in tokens if token in contractions])\n","#     return count"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WYF7gnAFB8M2","outputId":"c325499a-3684-4375-83f8-ff852b2c1027","executionInfo":{"status":"ok","timestamp":1681268250359,"user_tz":240,"elapsed":59871,"user":{"displayName":"Sam You","userId":"01133282480618762281"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["              label  avg_burstiness  avg_sentence_length  vocabulary_richness\n","count  15000.000000    1.500000e+04         15000.000000         15000.000000\n","mean       0.712400    1.636883e-18            23.021490             0.531113\n","std        0.452659    1.838844e-16            15.323685             0.061673\n","min        0.000000   -9.992007e-16             3.681818             0.187500\n","25%        0.000000   -1.315903e-16            17.727273             0.496063\n","50%        1.000000    0.000000e+00            20.818182             0.535376\n","75%        1.000000    1.362079e-16            25.000000             0.572687\n","max        1.000000    8.536589e-16           517.000000             0.836653\n","             label  avg_burstiness  avg_sentence_length  vocabulary_richness\n","count  4998.000000    4.998000e+03          4998.000000          4998.000000\n","mean      0.726090   -2.823280e-18            22.692180             0.533351\n","std       0.446008    1.849139e-16            12.634988             0.060592\n","min       0.000000   -7.678336e-16             3.666667             0.207469\n","25%       0.000000   -1.357941e-16            17.833333             0.497253\n","50%       1.000000   -1.534940e-18            20.750000             0.538462\n","75%       1.000000    1.306145e-16            24.875000             0.574556\n","max       1.000000    8.319646e-16           298.500000             0.777778\n"]}],"source":["##add these features to train and test sets \n","train_aug = train[\"label\"].to_frame()\n","test_aug = test[\"label\"].to_frame()\n","\n","# reset index\n","#temp_train = train_no_delim.reset_index(drop=True)\n","#temp_test = test_no_delim.reset_index(drop=True)\n","\n","#train_aug = extract_perplexity(train_no_delim, model, n)\n","#test_aug = extract_perplexity(test_no_delim, model, n)\n","\n","for func in extract_feature_functions: \n","  train_aug[func.__name__] = train['text'].apply(func)\n","  test_aug[func.__name__] = test['text'].apply(func)\n","\n","print(train_aug.describe())\n","print(test_aug.describe())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8LZ51S1ACqfn","outputId":"7cc511c3-2068-4f7b-8154-c4216c596c32","executionInfo":{"status":"ok","timestamp":1681268250360,"user_tz":240,"elapsed":24,"user":{"displayName":"Sam You","userId":"01133282480618762281"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['avg_burstiness', 'avg_sentence_length', 'vocabulary_richness'], dtype='object')\n"]}],"source":["#normalize columns\n","train_aug_normed = (train_aug - train_aug.mean()) / train_aug.std()\n","test_aug_normed = (test_aug - test_aug.mean()) / test_aug.std()\n","\n","train_aug_normed = train_aug_normed.drop(columns=['label'])\n","test_aug_normed = test_aug_normed.drop(columns=['label'])\n","print(train_aug_normed.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AX8OVeYvHWNp","outputId":"8c7c5bcb-cc88-4c33-f686-68617b8a4d38","executionInfo":{"status":"ok","timestamp":1681268271501,"user_tz":240,"elapsed":21162,"user":{"displayName":"Sam You","userId":"01133282480618762281"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["|   iter    |  target   | colsam... | learni... | max_depth | n_esti... | subsample |\n","-------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["3it [00:01,  1.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["| \u001b[0m1        \u001b[0m | \u001b[0m0.7266   \u001b[0m | \u001b[0m0.4176   \u001b[0m | \u001b[0m0.2661   \u001b[0m | \u001b[0m5.003    \u001b[0m | \u001b[0m311.6    \u001b[0m | \u001b[0m0.1476   \u001b[0m |\n"]},{"output_type":"stream","name":"stderr","text":["3it [00:05,  1.69s/it]\n"]},{"output_type":"stream","name":"stdout","text":["| \u001b[95m2        \u001b[0m | \u001b[95m0.7327   \u001b[0m | \u001b[95m0.09325  \u001b[0m | \u001b[95m0.1059   \u001b[0m | \u001b[95m13.64    \u001b[0m | \u001b[95m377.7    \u001b[0m | \u001b[95m0.5393   \u001b[0m |\n"]},{"output_type":"stream","name":"stderr","text":["3it [00:04,  1.55s/it]\n"]},{"output_type":"stream","name":"stdout","text":["| \u001b[0m3        \u001b[0m | \u001b[0m0.7325   \u001b[0m | \u001b[0m0.1169   \u001b[0m | \u001b[0m0.1586   \u001b[0m | \u001b[0m13.01    \u001b[0m | \u001b[0m376.5    \u001b[0m | \u001b[0m0.07359  \u001b[0m |\n"]},{"output_type":"stream","name":"stderr","text":["3it [00:06,  2.23s/it]\n"]},{"output_type":"stream","name":"stdout","text":["| \u001b[95m4        \u001b[0m | \u001b[95m0.7345   \u001b[0m | \u001b[95m0.02473  \u001b[0m | \u001b[95m0.08469  \u001b[0m | \u001b[95m27.73    \u001b[0m | \u001b[95m416.6    \u001b[0m | \u001b[95m0.4497   \u001b[0m |\n"]},{"output_type":"stream","name":"stderr","text":["3it [00:03,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["| \u001b[95m5        \u001b[0m | \u001b[95m0.7408   \u001b[0m | \u001b[95m0.9642   \u001b[0m | \u001b[95m0.08414  \u001b[0m | \u001b[95m5.153    \u001b[0m | \u001b[95m488.6    \u001b[0m | \u001b[95m0.9832   \u001b[0m |\n","=====================================================================================\n","{'target': 0.7408, 'params': {'colsample_bytree': 0.9641647097885488, 'learning_rate': 0.08414056345852251, 'max_depth': 5.153270861117222, 'n_estimators': 488.5829548308575, 'subsample': 0.9831666069167586}}\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# gamma,min_child_weight\n","def xgb_evaluate2(n_estimators,max_depth,subsample\n","                ,colsample_bytree,learning_rate):\n","    model=XGBClassifier(n_estimators=int(n_estimators),\n","                          max_depth=int(max_depth),\n","                          subsample=subsample,\n","                          colsample_bytree=colsample_bytree,\n","                          learning_rate=learning_rate,n_jobs=-1,\n","                          tree_method='gpu_hist',\n","                          predictor='gpu_predictor')\n","    rmse_scores=[]\n","    kf = KFold(n_splits = 3)\n","    for train_ix, test_ix in tqdm(kf.split(train_aug_normed)):\n","        X_train, X_test = train_aug_normed.iloc[train_ix], train_aug_normed.iloc[test_ix]\n","        Y_train, Y_test = ytrain[train_ix], ytrain[test_ix]\n","        model.fit(X_train,Y_train,sample_weight=class_weight.compute_sample_weight(class_weight='balanced', y=Y_train))\n","        pred = model.predict(X_test)\n","        rmse_scores.append(accuracy_score(Y_test,pred))\n","    val=np.mean(rmse_scores)\n","    return val\n","pbounds = {'max_depth': (5, 30),\n","           'n_estimators': (100, 800),\n","           \"subsample\":(0.001, 1),\n","           \"colsample_bytree\":(0.001,1),\n","           \"learning_rate\":(0.05,0.35)}\n","xgb_bo = BayesianOptimization(\n","        f=xgb_evaluate2,   # Objective function\n","        pbounds=pbounds,  # Value space\n","        verbose=2,  # \n","        random_state=1,\n",")\n","xgb_bo.maximize(init_points=2,   # Steps of random search\n","                   n_iter=3,    # Number of iterations to perform Bayesian optimization\n","                   acq='ei')\n","print(xgb_bo.max)\n","res_xgb = xgb_bo.max\n","params_xgb2 = res_xgb['params']\n","for key in params_xgb2:\n","    if key in [\"max_depth\",\"scale_pos_weight\",\"n_estimators\"]:\n","        params_xgb2[key]=int(params_xgb2[key])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":284},"id":"k7OqgRDAH7q8","outputId":"4bad0a12-cc64-4a82-e00e-74368cbd1525","executionInfo":{"status":"ok","timestamp":1681268275009,"user_tz":240,"elapsed":3526,"user":{"displayName":"Sam You","userId":"01133282480618762281"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["3it [00:02,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["0.7408\n"]},{"output_type":"execute_result","data":{"text/plain":["XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=0.9641647097885488, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.08414056345852251,\n","              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=5, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=488, n_jobs=-1, num_parallel_tree=None,\n","              predictor='gpu_predictor', random_state=None, ...)"],"text/html":["<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=0.9641647097885488, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.08414056345852251,\n","              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=5, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=488, n_jobs=-1, num_parallel_tree=None,\n","              predictor=&#x27;gpu_predictor&#x27;, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=0.9641647097885488, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.08414056345852251,\n","              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=5, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=488, n_jobs=-1, num_parallel_tree=None,\n","              predictor=&#x27;gpu_predictor&#x27;, random_state=None, ...)</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":55}],"source":["xgb_2=XGBClassifier(**params_xgb2,tree_method='gpu_hist',\n","                    predictor='gpu_predictor',n_jobs=-1)\n","rmse_scores=[]\n","kf = KFold(n_splits = 3)\n","for train_ix, test_ix in tqdm(kf.split(train_aug_normed)):\n","    X_train, X_test = train_aug_normed.iloc[train_ix], train_aug_normed.iloc[test_ix]\n","    Y_train, Y_test = ytrain[train_ix], ytrain[test_ix]\n","    xgb_2.fit(X_train,Y_train,sample_weight=class_weight.compute_sample_weight(class_weight='balanced', y=Y_train))\n","    pred = xgb_2.predict(X_test)\n","    rmse_scores.append(accuracy_score(Y_test,pred))\n","a=np.mean(rmse_scores)\n","print(a)\n","xgb_2.fit(train_aug_normed,ytrain,sample_weight=class_weight.compute_sample_weight(class_weight='balanced', y=ytrain))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2tpqnVvz2bzb","outputId":"7f9d047e-cd9d-4dc1-e6be-50bb6d1f6bb6","executionInfo":{"status":"ok","timestamp":1681268275009,"user_tz":240,"elapsed":8,"user":{"displayName":"Sam You","userId":"01133282480618762281"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[2, 1, 0]\n"]}],"source":["#order of importance for extracted features \n","filename = \"xgboost_model_extracted_features.model\"\n","if(save):\n","  xgb_2.save_model(GOOGLE_DRIVE_PATH + '/' + filename)\n","\n","top_3_indices = np.flip(np.argsort(xgb_2.feature_importances_))[:3].tolist()\n","print(top_3_indices)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2TRIFNZ9J6pm"},"source":["Glue BERT with features, get score from xgb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OAROtBSbJ16-"},"outputs":[],"source":["#glue features together\n","torch_train.shape\n","BERT_train = pd.DataFrame(torch_train)\n","BERT_test = pd.DataFrame(torch_test)\n","\n","# set to proper index\n","BERT_train = BERT_train.set_index(train_aug_normed.index)\n","BERT_test = BERT_test.set_index(test_aug_normed.index)\n","\n","glued_train = pd.concat([BERT_train, train_aug_normed], axis=1)\n","glued_test = pd.concat([BERT_test, test_aug_normed], axis=1)\n","\n","if(save):\n","  # save dataframe to a CSV file\n","  train_aug_normed.to_csv(GOOGLE_DRIVE_PATH +  '/extracted_features_train.csv')\n","  test_aug_normed.to_csv(GOOGLE_DRIVE_PATH +  '/extracted_features_test.csv')\n","  glued_train.to_csv(GOOGLE_DRIVE_PATH +  '/glued_train.csv')\n","  glued_test.to_csv(GOOGLE_DRIVE_PATH +  '/glued_test.csv')\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fmW_75PpO64m","outputId":"4e16ec86-104a-4adb-b742-9f78ae3cee54","executionInfo":{"status":"ok","timestamp":1681268424885,"user_tz":240,"elapsed":126691,"user":{"displayName":"Sam You","userId":"01133282480618762281"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["|   iter    |  target   | colsam... | learni... | max_depth | n_esti... | subsample |\n","-------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["3it [00:14,  4.76s/it]\n"]},{"output_type":"stream","name":"stdout","text":["| \u001b[0m1        \u001b[0m | \u001b[0m0.9451   \u001b[0m | \u001b[0m0.4176   \u001b[0m | \u001b[0m0.2661   \u001b[0m | \u001b[0m5.003    \u001b[0m | \u001b[0m311.6    \u001b[0m | \u001b[0m0.1476   \u001b[0m |\n"]},{"output_type":"stream","name":"stderr","text":["3it [00:36, 12.29s/it]\n"]},{"output_type":"stream","name":"stdout","text":["| \u001b[95m2        \u001b[0m | \u001b[95m0.9539   \u001b[0m | \u001b[95m0.09325  \u001b[0m | \u001b[95m0.1059   \u001b[0m | \u001b[95m13.64    \u001b[0m | \u001b[95m377.7    \u001b[0m | \u001b[95m0.5393   \u001b[0m |\n"]},{"output_type":"stream","name":"stderr","text":["3it [00:17,  5.80s/it]\n"]},{"output_type":"stream","name":"stdout","text":["| \u001b[0m3        \u001b[0m | \u001b[0m0.9422   \u001b[0m | \u001b[0m0.1169   \u001b[0m | \u001b[0m0.1586   \u001b[0m | \u001b[0m13.01    \u001b[0m | \u001b[0m376.5    \u001b[0m | \u001b[0m0.07359  \u001b[0m |\n"]},{"output_type":"stream","name":"stderr","text":["3it [00:34, 11.48s/it]\n"]},{"output_type":"stream","name":"stdout","text":["| \u001b[95m4        \u001b[0m | \u001b[95m0.9594   \u001b[0m | \u001b[95m0.3006   \u001b[0m | \u001b[95m0.1875   \u001b[0m | \u001b[95m19.65    \u001b[0m | \u001b[95m620.2    \u001b[0m | \u001b[95m0.4747   \u001b[0m |\n"]},{"output_type":"stream","name":"stderr","text":["3it [00:23,  7.85s/it]"]},{"output_type":"stream","name":"stdout","text":["| \u001b[0m5        \u001b[0m | \u001b[0m0.9593   \u001b[0m | \u001b[0m0.7364   \u001b[0m | \u001b[0m0.2571   \u001b[0m | \u001b[0m7.397    \u001b[0m | \u001b[0m572.2    \u001b[0m | \u001b[0m0.6522   \u001b[0m |\n","=====================================================================================\n","{'target': 0.9594, 'params': {'colsample_bytree': 0.30059873422918637, 'learning_rate': 0.18753881599226613, 'max_depth': 19.65344386715824, 'n_estimators': 620.1613755817489, 'subsample': 0.4747233877512554}}\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# gamma,min_child_weight\n","def xgb_evaluate3(n_estimators,max_depth,subsample\n","                ,colsample_bytree,learning_rate):\n","    model=XGBClassifier(n_estimators=int(n_estimators),\n","                          max_depth=int(max_depth),\n","                          subsample=subsample,\n","                          colsample_bytree=colsample_bytree,\n","                          learning_rate=learning_rate,n_jobs=-1,\n","                          tree_method='gpu_hist',\n","                          predictor='gpu_predictor')\n","    rmse_scores=[]\n","    kf = KFold(n_splits = 3)\n","    for train_ix, test_ix in tqdm(kf.split(glued_train)):\n","        X_train, X_test = glued_train.iloc[train_ix], glued_train.iloc[test_ix]\n","        Y_train, Y_test = ytrain[train_ix], ytrain[test_ix]\n","        model.fit(X_train,Y_train,sample_weight=class_weight.compute_sample_weight(class_weight='balanced', y=Y_train))\n","        pred = model.predict(X_test)\n","        rmse_scores.append(accuracy_score(Y_test,pred))\n","    val=np.mean(rmse_scores)\n","    return val\n","pbounds = {'max_depth': (5, 30),\n","           'n_estimators': (100, 800),\n","           \"subsample\":(0.001, 1),\n","           \"colsample_bytree\":(0.001,1),\n","           \"learning_rate\":(0.05,0.35)}\n","xgb_bo = BayesianOptimization(\n","        f=xgb_evaluate3,   # Objective function\n","        pbounds=pbounds,  # Value space\n","        verbose=2,  # \n","        random_state=1,\n",")\n","xgb_bo.maximize(init_points=2,   # Steps of random search\n","                   n_iter=3,    # Number of iterations to perform Bayesian optimization\n","                   acq='ei')\n","print(xgb_bo.max)\n","res_xgb = xgb_bo.max\n","params_xgb3 = res_xgb['params']\n","for key in params_xgb3:\n","    if key in [\"max_depth\",\"scale_pos_weight\",\"n_estimators\"]:\n","        params_xgb3[key]=int(params_xgb3[key])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":284},"id":"vU-yTxpMPF4P","outputId":"ee938fad-2af0-47c1-b878-2ece01314462","executionInfo":{"status":"ok","timestamp":1681268459244,"user_tz":240,"elapsed":34380,"user":{"displayName":"Sam You","userId":"01133282480618762281"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["3it [00:24,  8.21s/it]\n"]},{"output_type":"stream","name":"stdout","text":["0.9592666666666666\n"]},{"output_type":"execute_result","data":{"text/plain":["XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=0.7364426244740934, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.2571381009492539,\n","              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=7, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=572, n_jobs=-1, num_parallel_tree=None,\n","              predictor='gpu_predictor', random_state=None, ...)"],"text/html":["<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=0.7364426244740934, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.2571381009492539,\n","              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=7, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=572, n_jobs=-1, num_parallel_tree=None,\n","              predictor=&#x27;gpu_predictor&#x27;, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=0.7364426244740934, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.2571381009492539,\n","              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=7, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=572, n_jobs=-1, num_parallel_tree=None,\n","              predictor=&#x27;gpu_predictor&#x27;, random_state=None, ...)</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":59}],"source":["xgb_3=XGBClassifier(**params_xgb1,tree_method='gpu_hist',\n","                    predictor='gpu_predictor',n_jobs=-1)\n","rmse_scores=[]\n","kf = KFold(n_splits = 3)\n","for train_ix, test_ix in tqdm(kf.split(glued_train)):\n","    X_train, X_test = glued_train.iloc[train_ix], glued_train.iloc[test_ix]\n","    Y_train, Y_test = ytrain[train_ix], ytrain[test_ix]\n","    xgb_3.fit(X_train,Y_train,sample_weight=class_weight.compute_sample_weight(class_weight='balanced', y=Y_train))\n","    pred = xgb_3.predict(X_test)\n","    rmse_scores.append(accuracy_score(Y_test,pred))\n","a=np.mean(rmse_scores)\n","print(a)\n","xgb_3.fit(glued_train,ytrain,sample_weight=class_weight.compute_sample_weight(class_weight='balanced', y=ytrain))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dn8EZiGm3Zsj"},"outputs":[],"source":["filename = \"xgboost_model_combined.model\"\n","if(save):\n","  xgb_3.save_model(GOOGLE_DRIVE_PATH + '/' + filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cZUTwdKFA3C_","outputId":"a4cbbf37-a703-4ffa-c9d4-5e6d8cdd6492","executionInfo":{"status":"ok","timestamp":1681268459971,"user_tz":240,"elapsed":4,"user":{"displayName":"Sam You","userId":"01133282480618762281"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["11\n","11\n","17\n","17\n","[656, 155, 338, 749, 247, 528, 698, 38, 284, 631, 143, 769, 537, 94, 688, 444, 461, 770, 8, 403, 614, 61, 480, 581, 13, 619, 349, 254, 551, 397, 509, 426, 624, 176, 286, 514, 422, 645, 711, 664, 503, 157, 21, 337, 534, 232, 758, 69, 5, 466, 686, 379, 331, 672, 222, 162, 150, 138, 697, 759, 499, 166, 506, 687, 287, 20, 54, 460, 376, 453, 163, 59, 595, 477, 715, 750, 588, 737, 290, 634, 413, 225, 28, 273, 350, 370, 511, 281, 187, 662, 180, 302, 135, 360, 727, 175, 364, 674, 578, 419]\n"]}],"source":["xgb_1 = load_xgb_model(\"xgboost_model_embeddings.model\")\n","xgb_3 = load_xgb_model(\"xgboost_model_combined.model\")\n","top_10_indices_xgb1 = np.flip(np.argsort(xgb_1.feature_importances_))[:40].tolist()\n","top_10_indices_xgb3 = np.flip(np.argsort(xgb_3.feature_importances_))[:100].tolist()\n","#print(top_10_indices_xgb1)\n","\n","count = 0\n","for i in range(len(top_10_indices_xgb3)):\n","  if top_10_indices_xgb3[i] > 767:\n","    print(i)\n","    print(count)\n","  count += 1\n","print(top_10_indices_xgb3)\n","  # richness, sentence length"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M8uU-2DZHoER"},"outputs":[],"source":["#1input = \"Republican leaders have followed an emboldened base of conservative activists into what increasingly looks like a political cul-de-sac on the issue of abortion — a tightly confined absolutist position that has limited their options ahead of the 2024 election season, even as some in the party push for moderation. Last year’s Supreme Court decision overturning a woman’s constitutionally protected right to an abortion was supposed to send the issue of abortion access to the states, where local politicians were supposed to have the best sense of the electorate’s views. But the decision on Friday by a conservative judge in Texas, invalidating the Food and Drug Administration’s 23-year-old approval of the abortion pill mifepristone, showed the push for nationwide restrictions on abortion has continued since the high court’s nullification of Roe v. Wade. Days earlier, abortion was the central theme in a liberal judge’s landslide victory for a contested and pivotal seat on the state Supreme Court in Wisconsin. Some Republicans are warning that the uncompromising position of their party’s activist base could be leading them over an electoral cliff next year.\"\n","input = \"The California economy is facing a major downturn following an increase in major tech companies' layoffs and studio cutbacks. Companies like Uber, Lyft, and WeWork have made significant job cuts, leading to a surge in unemployment across the state. The film industry, which is a significant contributor to California's economy, has similarly been hit by the pandemic, leading to reductions in film projects and layoff of production crews. The state is now faced with the challenge of resurrecting its economy amid the ongoing pandemic, which could lead to an extended period of economic decline if not promptly and adequately addressed.\"\n","\n","#input = \"WASHINGTON — The world economy faces the increasing risk of a painful slowdown amid worries about the global banking system and concerns that rising interest rates could force banks to curtail lending, the International Monetary Fund said on Tuesday. The warning follows weeks of turmoil in the global banking sector, which included two bank failures in the United States and UBS’s takeover of Credit Suisse, brokered by the Swiss government. Fears that bank runs would ripple through the financial system have abated in recent weeks, but concerns that additional bank failures and tightening lending standards could slow economic output around the world remain. In its latest World Economic Outlook report, the I.M.F. made a slight reduction to its growth forecast for 2023, lowering it to 2.8 percent, from 2.9 percent in January. Growth for the year is expected to be much slower than the I.M.F. predicted a year ago, when it projected output of 3.4 percent.\"\n","#input = \"Emile Durkheim’s theories on collective effervescence and social solidarity can be used to explain what happens at a sporting event in the United States. Collective effervescence refers to the emotional excitement and energy that is generated when people come together in a group, and this can be seen at a sporting event as fans come together to support their team. This shared enthusiasm creates a sense of unity and belonging among the fans, and can lead to a heightened sense of social solidarity. This solidarity is strengthened by the shared emotions, values and beliefs of the fans, and the shared goal of supporting their team to victory.\"\n","#0input = \"ChatGPT is a large language model developed by OpenAI. It is trained on a massive dataset of text and is able to generate human-like responses to a wide range of prompts. It can be used for a variety of tasks such as language translation, text summarization, and conversation generation. It has been trained on a diverse set of internet text and is capable of understanding and generating text in a variety of languages and styles.\"\n","#input = \"my name is sam i eat green eggs and ham\"\n","\n","#input = \"The history of tea in Japan began as early as the 8th century, when the first known references were made in Japanese records. Tea became a drink of the religious classes in Japan when Japanese priests and envoys sent to China to learn about its culture brought tea to Japan. The Buddhist monks Kūkai and Saichō may have been the first to bring tea seeds to Japan. The first form of tea brought from China was probably brick tea. Tea became a drink of the royal classes when Emperor Saga encouraged the growth of tea plants. Seeds were imported from China, and cultivation in Japan began. Tea consumption became popular among the gentry during the 12th century, after the publication of Eisai's Kissa Yōjōki. Uji, with its strategic location near the capital at Kyoto, became Japan's first major tea-producing region during this period. Beginning in the 13th and 14th centuries, Japanese tea culture developed the distinctive features for which it is known today, and the Japanese tea ceremony emerged as a key component of that culture.\"\n","\n","#input = \"WASHINGTON — The world economy faces the increasing risk of a painful slowdown amid worries about the global banking system and concerns that rising interest rates could force banks to curtail lending, the International Monetary Fund said on Tuesday. The warning follows weeks of turmoil in the global banking sector, which included two bank failures in the United States and UBS’s takeover of Credit Suisse, brokered by the Swiss government. Fears that bank runs would ripple through the financial system have abated in recent weeks, but concerns that additional bank failures and tightening lending standards could slow economic output around the world remain. In its latest World Economic Outlook report, the I.M.F. made a slight reduction to its growth forecast for 2023, lowering it to 2.8 percent, from 2.9 percent in January. Growth for the year is expected to be much slower than the I.M.F. predicted a year ago, when it projected output of 3.4 percent.\"\n","\n","#input = \"Chinese merchants have long been key figures in the commercial life of Southeast Asia. They acted as important middlemen, providing moneylending services, acting as brokers, and operating tax farms. To the Dutch East India Company (VOC), they functioned as junior partners, intermediating with Javanese states, helping to negotiate trade agreements and oversee trading posts. Their unique ability to pool capital and relay commercial information through kinship networks and secret societies joined their outsider status and sheer economic necessity to make them ideal commercial brokers in a world of constant flux. In 17th century Java their role as commercial mediators was lucrative not only to Javanese states, but also to the VOC, making them essential to both. However, by the Java War (1825-1830), entire Chinese communities were massacred, and Sino-Javanese relationships soured in a complete reversal from previous patterns of cooperation. This paper seeks to examine the downturn of Sino-Javanese relations in the context of the VOC, indigenous Javanese, and the Chinese merchant class. I also examine how the anti-Sinicism that originated prior to the Java War carried forward into nationalist movements of the 20th century.\"\n","\n","#1input = \"NAPOLEON BONAPARTE was born at Ajaccio, in Corsica, on the 15th of August 1769; the original orthography of his name was Buonaparte, but he suppressed the \"u\" during his first campaign in Italy. His motives for so doing were merely to render the spelling conformable with the pronunciation, and to abridge his signature. He signed Buonaparte even after the famous 13th Vendemiaire. It has been affirmed that he was born in 1768, and that he represented himself to be a year younger than he really was. This is untrue. He always told me the 9th of August was his birthday, and, as I was born on the 9th of July 1769, our proximity of age served to strengthen our union and friendship when we were both at the Military College of Brienne. The false and absurd charge of Bonaparte having misrepresented his age, is decidedly refuted by a note in the register of M. Berton, sub-principal of the College of Brienne, in which it is stated that M. Napoleon de Buonaparte, ecuyer, born in the city of Ajaccio, in Corsica, on the 15th of August 1769, left the Royal Military College of Brienne on the 17th October 1784. The stories about his low extraction are alike devoid of foundation. His family was poor, and he was educated at the public expense, an advantage of which many honourable families availed themselves. A memorial addressed by his father, Charles Buonaparte, to the Minister of War states that his fortune had been reduced by the failure of some enterprise in which he had engaged, and by the injustice of the Jesuits, by whom he had been deprived of an inheritance. The object of this memorial was to solicit a sub-lieutenant's commission for Napoleon, who was then fourteen years of age, and to get Lucien entered a pupil of the Military College. The Minister wrote on the back of the memorial, Give the usual answer, if there be a vacancy; and on the margin are these words This gentleman has been informed that his request is inadmissible as long as his second son remains at the school of Brienne. Two brothers cannot be placed at the same time in the military schools.When Napoleon was fifteen he was sent to Paris until he should attain the requisite age for entering the army. Lucien was not received into the College of Brienne, at least not until his brother had quitted the Military School of Paris.\"\n","\n","#input = \"In the sprawling countryside of 19th century Russia, there lived a young girl named Anna. She was the daughter of a wealthy landowner and had been raised with every advantage that her privileged upbringing could offer. But despite her comfortable life, Anna felt a restlessness in her soul. She longed for something more than the empty social conventions and petty politics of her world. And so when she met a dashing young officer named Alexei, she was immediately drawn to his rebellious spirit and fierce independence. Their relationship began as a simple flirtation, a game of cat and mouse that soon escalated into a passionate affair. As Anna and Alexei spent more and more time together, they became increasingly reckless in their actions, risking everything for the sake of their love. But as their affair grew more intense, Anna began to feel the weight of society's expectations bearing down upon her. She knew that her relationship with Alexei could never be accepted by her family or by the conservative society in which she lived.\"\n","#input = \"Happy families are all alike; every unhappy family is unhappy in its own way.Everything was in confusion in the Oblonskys’ house. The wife had discovered that the husband was carrying on an intrigue with a French girl, who had been a governess in their family, and she had announced to her husband that she could not go on living in the same house with him. This position of affairs had now lasted three days, and not only the husband and wife themselves, but all the members of their family and household, were painfully conscious of it. Every person in the house felt that there was no sense in their living together, and that the stray people brought together by chance in any inn had more in common with one another than they, the members of the family and household of the Oblonskys. The wife did not leave her own room, the husband had not been at home for three days. The children ran wild all over the house; the English governess quarreled with the housekeeper, and wrote to a friend asking her to look out for a new situation for her; the man-cook had walked off the day before just at dinner time; the kitchen-maid, and the coachman had given warning. Three days after the quarrel, Prince Stepan Arkadyevitch Oblonsky—Stiva, as he was called in the fashionable world—woke up at his usual hour, that is, at eight o’clock in the morning, not in his wife’s bedroom, but on the leather-covered sofa in his study. He turned over his stout, well-cared-for person on the springy sofa, as though he would sink into a long sleep again; he vigorously embraced the pillow on the other side and buried his face in it; but all at once he jumped up, sat up on the sofa, and opened his eyes. “Yes, yes, how was it now?” he thought, going over his dream. “Now, how was it? To be sure! Alabin was giving a dinner at Darmstadt; no, not Darmstadt, but something American. Yes, but then, Darmstadt was in America. Yes, Alabin was giving a dinner on glass tables, and the tables sang, Il mio tesoro—not Il mio tesoro though, but something better, and there were some sort of little decanters on the table, and they were women, too,” he remembered. Stepan Arkadyevitch’s eyes twinkled gaily, and he pondered with a smile. “Yes, it was nice, very nice. There was a great deal more that was delightful, only there’s no putting it into words, or even expressing it in one’s thoughts awake.” And noticing a gleam of light peeping in beside one of the serge curtains, he cheerfully dropped his feet over the edge of the sofa, and felt about with them for his slippers, a present on his last birthday, worked for him by his wife on gold-colored morocco. And, as he had done every day for the last nine years, he stretched out his hand, without getting up, towards the place where his dressing-gown always hung in his bedroom. And thereupon he suddenly remembered that he was not sleeping in his wife’s room, but in his study, and why: the smile vanished from his face, he knitted his brows. “Ah, ah, ah! Oo!...” he muttered, recalling everything that had happened. And again every detail of his quarrel with his wife was present to his imagination, all the hopelessness of his position, and worst of all, his own fault. “Yes, she won’t forgive me, and she can’t forgive me. And the most awful thing about it is that it’s all my fault—all my fault, though I’m not to blame. That’s the point of the whole situation,” he reflected. “Oh, oh, oh!” he kept repeating in despair, as he remembered the acutely painful sensations caused him by this quarrel. Most unpleasant of all was the first minute when, on coming, happy and good-humored, from the theater, with a huge pear in his hand for his wife, he had not found his wife in the drawing-room, to his surprise had not found her in the study either, and saw her at last in her bedroom with the unlucky letter that revealed everything in her hand. She, his Dolly, forever fussing and worrying over household details, and limited in her ideas, as he considered, was sitting perfectly still with the letter in her hand, looking at him with an expression of horror, despair, and indignation. “What’s this? this?” she asked, pointing to the letter. And at this recollection, Stepan Arkadyevitch, as is so often the case, was not so much annoyed at the fact itself as at the way in which he had met his wife’s words. There happened to him at that instant what does happen to people when they are unexpectedly caught in something very disgraceful. He did not succeed in adapting his face to the position in which he was placed towards his wife by the discovery of his fault. Instead of being hurt, denying, defending himself, begging forgiveness, instead of remaining indifferent even—anything would have been better than what he did do—his face utterly involuntarily (reflex spinal action, reflected Stepan Arkadyevitch, who was fond of physiology)—utterly involuntarily assumed its habitual, good-humored, and therefore idiotic smile. This idiotic smile he could not forgive himself. Catching sight of that smile, Dolly shuddered as though at physical pain, broke out with her characteristic heat into a flood of cruel words, and rushed out of the room. Since then she had refused to see her husband. “It’s that idiotic smile that’s to blame for it all,” thought Stepan Arkadyevitch. “But what’s to be done? What’s to be done?” he said to himself in despair, and found no answer.\""]},{"cell_type":"code","source":["#input = \"blah\""],"metadata":{"id":"fiKSWVzQcKVl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scores = [1, 1, 1, 1, 1, 1]"],"metadata":{"id":"hhMfwzhsavnq"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UUvI9KdGB9UZ","outputId":"ff8df836-2103-43e5-a0e5-4cdf4dff09bf","executionInfo":{"status":"ok","timestamp":1681269012428,"user_tz":240,"elapsed":315,"user":{"displayName":"Sam You","userId":"01133282480618762281"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 18.36it/s]"]},{"output_type":"stream","name":"stdout","text":["[1]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["temp_df = pd.DataFrame(data = [input], columns = [\"text\"])\n","\n","g = preprocess_data(temp_df)\n","\n","pred = xgb_3.predict(g)\n","print(pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pjXKeY6ABcmi"},"outputs":[],"source":["if(save):\n","  # save y_train and y_test dataframes to CSV files\n","  train[\"label\"].to_csv(GOOGLE_DRIVE_PATH + '/y_train.csv')\n","  test[\"label\"].to_csv(GOOGLE_DRIVE_PATH + '/y_test.csv')\n"]},{"cell_type":"markdown","metadata":{"id":"9puqo0a7RaPb"},"source":["Test Set on Saved Xgboost Models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Vk0SKSh_CYv","executionInfo":{"status":"ok","timestamp":1681268816553,"user_tz":240,"elapsed":6179,"user":{"displayName":"Sam You","userId":"01133282480618762281"}},"outputId":"65bf2661-4b13-46ee-a831-9527bea5e446"},"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n","       ...\n","       '761', '762', '763', '764', '765', '766', '767', 'avg_burstiness',\n","       'avg_sentence_length', 'vocabulary_richness'],\n","      dtype='object', length=771)\n","Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n","       ...\n","       '761', '762', '763', '764', '765', '766', '767', 'avg_burstiness',\n","       'avg_sentence_length', 'vocabulary_richness'],\n","      dtype='object', length=771)\n","Xgboost model trained on BERT encodings Test accuracy 0.9645858343337335\n","Xgboost model trained on extracted features Test Accuracy 0.7360944377751101\n","Xgboost model trained on combined training set Test Accuracy 0.963985594237695\n"]}],"source":["# load y_train and y_test dataframes from the CSV files with index\n","y_train = pd.read_csv(GOOGLE_DRIVE_PATH+'/y_train.csv', index_col=0)\n","y_test = pd.read_csv(GOOGLE_DRIVE_PATH+'/y_test.csv', index_col=0)\n","# print(y_train.head)\n","# print(y_test.head)\n","\n","#if you want to use the models we just trained \n","loaded_model_1 = load_xgb_model(\"xgboost_model_embeddings.model\") #xgb_1\n","loaded_model_2 = load_xgb_model(\"xgboost_model_extracted_features.model\") #xgb_2\n","loaded_model_3 = load_xgb_model(\"xgboost_model_combined.model\") #xgb_3\n","\n","torch_train = torch.load( GOOGLE_DRIVE_PATH +  '/torch_embeddings_train.pt')\n","torch_test = torch.load( GOOGLE_DRIVE_PATH +  '/torch_embeddings_test.pt')\n","\n","train_aug_normed = pd.read_csv(GOOGLE_DRIVE_PATH +  '/extracted_features_train.csv', index_col=0)\n","test_aug_normed = pd.read_csv(GOOGLE_DRIVE_PATH +  '/extracted_features_test.csv', index_col=0)\n","\n","glued_train = pd.read_csv(GOOGLE_DRIVE_PATH +  '/glued_train.csv', index_col=0)\n","glued_test = pd.read_csv(GOOGLE_DRIVE_PATH +  '/glued_test.csv', index_col=0)\n","\n","\n","print(glued_train.columns)\n","print(glued_test.columns)\n","\n","##first model-- BERT encodings\n","# Predict on the test data\n","ypred = loaded_model_1.predict(torch_test)\n","# Calculate the accuracy of the predictions\n","accuracy = accuracy_score(y_test, ypred)\n","print(\"Xgboost model trained on BERT encodings Test accuracy\", accuracy)\n","\n","##second model-- extracted feature\n","# Predict on the test data\n","# test_aug_normed.drop('Unnamed: 0', axis=1, inplace=True)\n","ypred = loaded_model_2.predict(test_aug_normed)\n","# Calculate the accuracy of the predictions\n","accuracy = accuracy_score(y_test, ypred)\n","print(\"Xgboost model trained on extracted features Test Accuracy\", accuracy)\n","\n","\n","##second model-- extracted feature\n","# glued_test.drop('Unnamed: 0', axis=1, inplace=True)\n","ypred = loaded_model_3.predict(glued_test)\n","# Calculate the accuracy of the predictions\n","accuracy = accuracy_score(y_test, ypred)\n","print(\"Xgboost model trained on combined training set Test Accuracy\", accuracy)"]},{"cell_type":"markdown","source":[],"metadata":{"id":"M-8r7UVnm6x4"}},{"cell_type":"markdown","metadata":{"id":"XqLpYmD1S1ME"},"source":["PyCaret To Find Best Classifier Model"]},{"cell_type":"markdown","metadata":{"id":"UaR6KKpa7Eab"},"source":["PyCaret Notebook\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NROYaUh2F1N7"},"source":["Generalizability-- Wikipedia With Different GPT Models \n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x5_oM-JU-RbP","executionInfo":{"status":"ok","timestamp":1681268832052,"user_tz":240,"elapsed":15516,"user":{"displayName":"Sam You","userId":"01133282480618762281"}},"outputId":"b219225f-49e1-4a2e-cddb-34f243dd0c7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openai\n","  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.4 yarl-1.8.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting xxhash\n","  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets) (3.8.4)\n","Collecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.11.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, responses, multiprocess, datasets\n","Successfully installed datasets-2.11.0 dill-0.3.6 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0\n"]}],"source":["!pip install openai\n","!pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JM1Am6TkJMVK"},"outputs":[],"source":["#helper functions\n","import json\n","import openai\n","openai.api_key = \"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\"\n","def gpt_request(prompt, model = \"text-curie-001\" ):\n","    max_tokens = 1000\n","    response = openai.Completion.create(\n","          model=model,\n","          prompt=prompt,\n","          temperature=0.2,\n","          max_tokens=max_tokens,\n","    )\n","    return response.choices[0].text\n","  \n","def chatgpt_request(prompt):\n","    response = openai.ChatCompletion.create(\n","          model=\"gpt-3.5-turbo-0301\",\n","          messages=[{\"role\": \"user\", \"content\": prompt}, ],\n","          temperature=0.2,\n","      )\n","    return response.choices[0].message.content\n","    \n","def get_human_wikis(g):\n","  df_human_intros = pd.read_csv(GOOGLE_DRIVE_PATH +'/wiki_intros_human.csv')\n","  subset_cols = g[['wiki_intro', 'title']]\n","  subset_cols[\"label\"] = 1\n","  df_human_intros = pd.concat([df_human_intros, subset_cols])\n","  return df_human_intros"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OVOk-gbOK6Ys","executionInfo":{"status":"ok","timestamp":1681268832053,"user_tz":240,"elapsed":10,"user":{"displayName":"Sam You","userId":"01133282480618762281"}},"outputId":"29814bdc-3a65-40f9-e635-b69365c88dde"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import tensorflow as tf\n","import xgboost\n","from tqdm import tqdm\n","from collections import Counter\n","import nltk\n","from nltk import word_tokenize\n","from nltk.lm.preprocessing import padded_everygram_pipeline\n","from nltk.lm import MLE\n","from collections import Counter\n","nltk.download('punkt')\n","import nltk\n","from nltk.lm import MLE\n","from nltk.lm.preprocessing import padded_everygram_pipeline\n","from sklearn.metrics import accuracy_score \n","\n","\n","def preprocess_data(df):\n","  d = df['text'].apply(lambda x: dataPreprocessing(x))\n","  data = d.to_frame()\n","  embeddings = []\n","  for row in tqdm(data['text']):\n","      input = row\n","      embeddings.append(model([input]).cpu().detach().numpy())\n","  embeddings = np.array(embeddings).reshape(-1,768)\n","  # return embeddings\n","  features = pd.DataFrame()\n","  for func in extract_feature_functions: \n","    features[func.__name__] = df['text'].apply(func)\n","  features = (features - features.mean()) / features.std()\n","  embs = pd.DataFrame(embeddings)\n","  features = features.set_index(embs.index)\n","  g = pd.concat([embs, features], axis=1)\n","  return g"]},{"cell_type":"markdown","metadata":{"id":"6cSsum2K_0JI"},"source":["\n","Index(['id', 'url', 'title', 'wiki_intro', 'generated_intro', 'title_len',\n","       'wiki_intro_len', 'generated_intro_len', 'prompt', 'generated_text',\n","       'prompt_tokens', 'generated_text_tokens'],\n","      dtype='object')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lir367Y4F-x3"},"outputs":[],"source":["# # Creating the GPT Wiki Dataset with Diff Models\n","# df_human_intros = get_human_wikis(generalized_set)\n","\n","# # print(df_human_intros.shape)\n","# # print(df_human_intros.head)\n","\n","# resps = {\"title\": [], \"text-davinci-003\": [], \"chatgpt\": [], \"label\": [] }\n","# i = 0\n","# for title in df_human_intros[\"title\"].tolist()[:]:\n","#   prompt = \"Write a wikipedia intro on \"\n","#   prompt = prompt + title\n","#   prompt += \" that is around 200 words\"\n","#   resps[\"title\"].append(title)\n","#   resps[\"label\"].append(0)\n","#   resps[\"text-davinci-003\"].append(gpt_request(prompt, \"text-davinci-003\"))\n","#   resps[\"chatgpt\"].append(chatgpt_request(prompt))\n","#   if (i % 10 == 0):\n","#     df = pd.DataFrame.from_dict(resps)\n","#     df.to_csv(GOOGLE_DRIVE_PATH +'/ai_wiki_intros.csv', mode='a', header=not os.path.exists(GOOGLE_DRIVE_PATH +'/ai_wiki_intros.csv'), index=False)\n","#     resps = {\"title\": [], \"text-davinci-003\": [], \"chatgpt\": [], \"label\": [] }\n","#   i+=1\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Gr_lz-jNkmS","executionInfo":{"status":"ok","timestamp":1681268948171,"user_tz":240,"elapsed":32490,"user":{"displayName":"Sam You","userId":"01133282480618762281"}},"outputId":"ba198f87-d68b-4194-80ba-148ea8b8fbac"},"outputs":[{"output_type":"stream","name":"stdout","text":["<bound method NDFrame.head of                     title                                   text-davinci-003  \\\n","0             Formula One  \\n\\nFormula One, also known as F1 or Grand Pri...   \n","1               Hominidae  \\n\\nHominidae is a taxonomic family of primate...   \n","2            Genghis Khan  \\n\\nGenghis Khan (c. 1162 – August 18, 1227) w...   \n","3            The Dead Sea  \\n\\nThe Dead Sea, also known as the Salt Sea, ...   \n","4                    Rice  \\n\\nRice is a cereal grain that is the most wi...   \n","..                    ...                                                ...   \n","357      Giuliana Attenni  \\n\\nGiuliana Attenni (born April 17, 1975) is ...   \n","358       Yegor Solyankin  \\n\\nYegor Solyankin (born August 28, 1983) is ...   \n","359     Crucified Barbara  \\n\\nCrucified Barbara is a Swedish hard rock b...   \n","360  Quiero (Selena song)  \\n\\n\"Quiero\" is a song by American singer Sele...   \n","361        Werribee River  \\n\\nThe Werribee River is a major river in Vic...   \n","\n","                                               chatgpt  label  \n","0    Formula One (F1) is the highest class of singl...      0  \n","1    Hominidae is a family of primates that include...      0  \n","2    Genghis Khan, born Temujin, was the founder an...      0  \n","3    The Dead Sea is a saltwater lake located in th...      0  \n","4    Rice is a staple food and one of the most impo...      0  \n","..                                                 ...    ...  \n","357  Giuliana Attenni is an Italian journalist, aut...      0  \n","358  Yegor Solyankin was a Russian professional foo...      0  \n","359  Crucified Barbara was a Swedish all-female har...      0  \n","360  \"Quiero\" is a song by the late Tejano singer S...      0  \n","361  Werribee River is a river located in the weste...      0  \n","\n","[362 rows x 4 columns]>\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 643/643 [00:16<00:00, 37.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["0      1\n","1      1\n","2      1\n","3      1\n","4      1\n","      ..\n","357    0\n","358    0\n","359    0\n","360    0\n","361    0\n","Name: label, Length: 643, dtype: int64\n","[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n"," 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n"," 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n","Xgboost model run on ChatGPT Responses Test Accuracy for text-davinci-003 reviews 0.9564541213063764\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 643/643 [00:12<00:00, 51.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["0      1\n","1      1\n","2      1\n","3      1\n","4      1\n","      ..\n","357    0\n","358    0\n","359    0\n","360    0\n","361    0\n","Name: label, Length: 643, dtype: int64\n","[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n"," 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n"," 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n"," 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n"," 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","Xgboost model run on ChatGPT Responses Test Accuracy for chatgpt reviews 0.9533437013996889\n"]}],"source":["#our test set has 281 AI generated around 200 word intros\n","df_human_wiki = get_human_wikis(generalized_set)[:281]\n","df_human_wiki = df_human_wiki.rename(columns={'wiki_intro': 'text'})\n","\n","\n","df_ai_wiki = pd.read_csv(GOOGLE_DRIVE_PATH +'/ai_wiki_intros.csv')\n","\n","print(df_ai_wiki.head)\n","types = [\"text-davinci-003\", \"chatgpt\"]\n","\n","best_model = load_xgb_model(\"xgboost_model_combined.model\")\n","for t in types:\n","  df_t = df_ai_wiki[[t, 'label', 'title']]\n","  df_t = df_t.rename(columns={t: 'text'})\n","  # print(df_t.head)\n","  # print(df_ai_wiki.head)\n","  comb = pd.concat([df_human_wiki, df_t])\n","  # print(comb.head)\n","  ytest = comb[\"label\"]\n","  comb = comb[[\"text\"]]\n","  data = preprocess_data(comb)\n","  ypred = best_model.predict(data)\n","  print(ytest)\n","  print(ypred)\n","  # Calculate the accuracy of the predictions\n","  accuracy = accuracy_score(ytest, ypred)\n","  print(f\"Xgboost model run on ChatGPT Responses Test Accuracy for {t} reviews\", accuracy)\n"]},{"cell_type":"code","source":["print(df_ai_wiki.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VkEeJ5nQmTaF","executionInfo":{"status":"ok","timestamp":1681268879729,"user_tz":240,"elapsed":17,"user":{"displayName":"Sam You","userId":"01133282480618762281"}},"outputId":"147f2021-9f68-49f8-a020-5501cdfc5685"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(362, 4)\n"]}]},{"cell_type":"markdown","metadata":{"id":"CMTGiPbS5gsq"},"source":["Generalizability-- Product Reviews\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZoFrOgO_5mDc"},"outputs":[],"source":["#Get human review dataset\n","import pandas as pd\n","# from datasets import load_dataset\n","# product_data = {\"product_title\": [], \"review_body\": []}\n","# configs = ['Wireless_v1_00', 'Watches_v1_00', 'Video_Games_v1_00', 'Video_DVD_v1_00', 'Toys_v1_00', 'Tools_v1_00', 'Sports_v1_00', 'Software_v1_00', 'Shoes_v1_00', 'Pet_Products_v1_00', 'Personal_Care_Appliances_v1_00', 'PC_v1_00', 'Outdoors_v1_00', 'Office_Products_v1_00', 'Musical_Instruments_v1_00', 'Music_v1_00', 'Mobile_Electronics_v1_00', 'Mobile_Apps_v1_00', 'Major_Appliances_v1_00', 'Luggage_v1_00', 'Lawn_and_Garden_v1_00', 'Kitchen_v1_00', 'Jewelry_v1_00', 'Home_Improvement_v1_00', 'Home_Entertainment_v1_00', 'Home_v1_00', 'Health_Personal_Care_v1_00', 'Grocery_v1_00', 'Gift_Card_v1_00', 'Furniture_v1_00', 'Electronics_v1_00', 'Digital_Video_Games_v1_00', 'Digital_Video_Download_v1_00', 'Digital_Software_v1_00', 'Digital_Music_Purchase_v1_00', 'Digital_Ebook_Purchase_v1_00', 'Camera_v1_00', 'Books_v1_00', 'Beauty_v1_00', 'Baby_v1_00', 'Automotive_v1_00', 'Apparel_v1_00', 'Digital_Ebook_Purchase_v1_01', 'Books_v1_01', 'Books_v1_02']\n","# for c in configs:\n","#   dataset = load_dataset(\"amazon_us_reviews\", c)\n","#   # get a small random sample of the dataset\n","#   for s in dataset[\"train\"]:\n","#       title = s['product_title']\n","#       body = s['review_body']\n","#       if title not in product_data[\"product_title\"]:\n","#           product_data[\"product_title\"].append(title)\n","#           product_data[\"review_body\"].append(body)\n","#       if(len(product_data[\"product_title\"]) > 100):\n","#         df = pd.DataFrame(product_data)\n","#         df[\"label\"] = 1\n","#         df.to_csv(GOOGLE_DRIVE_PATH +'/human_reviews.csv', mode='a', header=not os.path.exists(GOOGLE_DRIVE_PATH +'/human_reviews.csv'), index=False)\n","#         product_data = {\"product_title\": [], \"review_body\": []}\n","\n","#add label for train\n","# human['label'] = 1.0\n","# gpt['label'] = 0.0\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zcWn83n1vDxt"},"outputs":[],"source":["#create GPT review dataset\n","\n","# resps = {\"product_title\": [], \"text-curie-001\": [],  \"text-davinci-003\": [], \"chatgpt\": [] }\n","# i = 0\n","# for product in df_human_reviews[\"product_title\"].tolist()[:]:\n","#   prompt = \"write me an Amazon review for the \"\n","#   prompt = prompt + product\n","#   resps[\"product_title\"].append(product)\n","#   resps[\"label\"] = 0\n","#   resps[\"text-curie-001\"].append(gpt_request(prompt))\n","#   resps[\"text-davinci-003\"].append(gpt_request(prompt, \"text-davinci-003\"))\n","#   resps[\"chatgpt\"].append(chatgpt_request(prompt))\n","#   print(product)\n","#   print(i)\n","#   if (i % 5 == 0):\n","#     df = pd.DataFrame.from_dict(resps)\n","#     df.to_csv(GOOGLE_DRIVE_PATH +'/ai_reviews.csv', mode='a', header=not os.path.exists(GOOGLE_DRIVE_PATH +'/ai_reviews.csv'), index=False)\n","#     resps =  {\"product_title\": [], \"text-curie-001\": [],  \"text-davinci-003\": [], \"chatgpt\": [] }\n","#   i+=1\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"id":"TdV-4IVA4lef","executionInfo":{"status":"error","timestamp":1681268894938,"user_tz":240,"elapsed":15223,"user":{"displayName":"Sam You","userId":"01133282480618762281"}},"outputId":"1f9ce7b6-1d4e-497f-c629-929f9aa7e938"},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-96-028064624596>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mytest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mcomb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-90-0e34767f6f74>\u001b[0m in \u001b[0;36mpreprocess_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdataPreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[0;32m-> 4771\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4773\u001b[0m     def _reduce(\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","\u001b[0;32m<ipython-input-90-0e34767f6f74>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdataPreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-35-331b5a3d672a>\u001b[0m in \u001b[0;36mdataPreprocessing\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdataPreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremoveHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"@\\w+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# removing mentions (@)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"]}],"source":["# Load the DataFrame from the CSV file\n","df_human_reviews = pd.read_csv(GOOGLE_DRIVE_PATH +'/human_reviews.csv')[:250]\n","df_human_reviews = pd.read_csv(GOOGLE_DRIVE_PATH +'/ai_reviews.csv')[:250]\n","\n","df_human_reviews = df_human_reviews.rename(columns={'review_body': 'text'})[:245]\n","df_human_reviews[\"label\"] = 1\n","types = [\"text-curie-001\",  \"text-davinci-003\", \"chatgpt\"]\n","df_ai_reviews = pd.read_csv(GOOGLE_DRIVE_PATH +'/ai_reviews.csv')\n","best_model = load_xgb_model(\"xgboost_model_combined.model\")  \n","for t in types:\n","  cols = []\n","  df_t = df_ai_reviews[['product_title', t, 'label']]\n","  df_t = df_t.rename(columns={t: 'text'})\n","  comb = pd.concat([df_human_reviews, df_t])\n","  ytest = comb[\"label\"]\n","  comb = comb[[\"text\"]]\n","  data = preprocess_data(comb)\n","  ypred = best_model.predict(data)\n","  print(ytest)\n","  print(ypred)\n","  # Calculate the accuracy of the predictions\n","  accuracy = accuracy_score(ytest, ypred)\n","  print(f\"Xgboost model run on Amazon product review Test Accuracy for {t} reviews\", accuracy)\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}